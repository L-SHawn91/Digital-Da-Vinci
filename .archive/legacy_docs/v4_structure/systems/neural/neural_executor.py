"""
ğŸ§  ì‹ ê²½ ì‹¤í–‰ì (Neural Executor)
ì‹ ê²½ê³„ ëª¨ë¸ í• ë‹¹ì„ ê¸°ë°˜ìœ¼ë¡œ ì‹¤ì œ ì‘ì—… ì‹¤í–‰

ì—­í• : ì‹ ê²½ ë¼ìš°í„°ì—ì„œ ì„ íƒí•œ ëª¨ë¸ë¡œ ì‹¤ì œ ì‘ì—… ì‹¤í–‰
íŠ¹ì§•: ëª¨ë¸ í˜¸ì¶œ, í† í° ì¶”ì , ê²°ê³¼ í‰ê°€, ì ìˆ˜ ì—…ë°ì´íŠ¸
"""

import os
import json
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, Callable, Optional
from enum import Enum


class ExecutionStatus(Enum):
    """ì‹¤í–‰ ìƒíƒœ"""
    SUCCESS = "success"
    PARTIAL = "partial"
    FAILURE = "failure"
    API_ERROR = "api_error"
    TIMEOUT = "timeout"


class NeuralExecutor:
    """ì‹ ê²½ê³„ ê¸°ë°˜ ì‘ì—… ì‹¤í–‰ì"""
    
    def __init__(self):
        self.registry_path = Path(__file__).parent / "neural_model_registry.json"
        self.execution_log_path = Path(__file__).parent / "execution_log.json"
        self.registry = self._load_registry()
        self.execution_log = self._load_execution_log()
    
    def _load_registry(self) -> Dict:
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        try:
            with open(self.registry_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            return {"models": {}}
    
    def _load_execution_log(self) -> Dict:
        """ì‹¤í–‰ ë¡œê·¸ ë¡œë“œ"""
        try:
            with open(self.execution_log_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            return {"executions": []}
    
    def execute_with_neural_routing(
        self,
        task_id: str,
        task_name: str,
        neural_level: str,
        task_func: Callable,
        timeout_seconds: int = 30,
        *args,
        **kwargs
    ) -> Dict:
        """
        ì‹ ê²½ ë¼ìš°íŒ…ì„ í†µí•œ ì‘ì—… ì‹¤í–‰
        
        Args:
            task_id: ì‘ì—… ID
            task_name: ì‘ì—… ì´ë¦„
            neural_level: L1-L4 ì‹ ê²½ê³„ ë ˆë²¨
            task_func: ì‹¤í–‰í•  í•¨ìˆ˜
            timeout_seconds: íƒ€ì„ì•„ì›ƒ
            *args, **kwargs: task_funcì— ì „ë‹¬í•  ì¸ì
        
        Returns:
            ì‹¤í–‰ ê²°ê³¼ ë° í‰ê°€
        """
        
        start_time = time.time()
        start_datetime = datetime.now().isoformat()
        
        # 1ë‹¨ê³„: ì‹ ê²½ ë¼ìš°íŒ…ìœ¼ë¡œ ìµœì  ëª¨ë¸ ì„ íƒ
        routing_result = self._route_to_model(neural_level)
        model_name = routing_result.get("model")
        
        if not model_name:
            return {
                "task_id": task_id,
                "task_name": task_name,
                "neural_level": neural_level,
                "status": ExecutionStatus.API_ERROR.value,
                "error": "ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ ì—†ìŒ",
                "timestamp": start_datetime,
                "duration_ms": 0
            }
        
        # 2ë‹¨ê³„: ì‘ì—… ì‹¤í–‰
        execution_result = self._execute_task(
            task_func,
            model_name,
            timeout_seconds,
            *args,
            **kwargs
        )
        
        end_time = time.time()
        duration_ms = int((end_time - start_time) * 1000)
        
        # 3ë‹¨ê³„: ê²°ê³¼ í‰ê°€
        quality_score = self._evaluate_result(execution_result)
        
        # 4ë‹¨ê³„: ëª¨ë¸ ì ìˆ˜ ì—…ë°ì´íŠ¸
        tokens_used = execution_result.get("tokens_used", 0)
        self._update_model_score(
            model_name,
            neural_level,
            execution_result["status"],
            quality_score,
            tokens_used,
            duration_ms
        )
        
        # 5ë‹¨ê³„: ê²°ê³¼ ë°˜í™˜
        result = {
            "task_id": task_id,
            "task_name": task_name,
            "neural_level": neural_level,
            "model": model_name,
            "neurotransmitter": routing_result.get("neurotransmitter"),
            "status": execution_result["status"],
            "quality_score": quality_score,
            "tokens_used": tokens_used,
            "duration_ms": duration_ms,
            "response_time_percentile": self._get_response_percentile(model_name, duration_ms),
            "timestamp": start_datetime,
            "end_timestamp": datetime.now().isoformat(),
            "result": execution_result.get("result"),
            "error": execution_result.get("error")
        }
        
        # ë¡œê·¸ì— ì €ì¥
        self.execution_log["executions"].append(result)
        self._save_execution_log()
        
        return result
    
    def _route_to_model(self, neural_level: str) -> Dict:
        """ì‹ ê²½ ë¼ìš°íŒ… (ìµœì  ëª¨ë¸ ì„ íƒ)"""
        
        best_model = None
        best_score = -1
        
        for model_name, model_data in self.registry["models"].items():
            # API í‚¤ í™•ì¸
            api_key_env = model_data.get("api_key_env")
            if not api_key_env or not os.getenv(api_key_env):
                continue
            
            # ì‹ ê²½ê³„ ë ˆë²¨ ì ìˆ˜
            if neural_level not in model_data["levels"]:
                continue
            
            level_score = model_data["levels"][neural_level]["score"]
            
            # í† í° ì²´í¬
            tokens = model_data["daily_tokens"]
            if tokens["used"] >= tokens["limit"] * 0.9:
                level_score *= 0.3
            
            if level_score > best_score:
                best_score = level_score
                best_model = model_name
        
        if not best_model:
            return {"model": None}
        
        return {
            "model": best_model,
            "score": best_score,
            "neurotransmitter": self.registry["models"][best_model].get("neurotransmitter")
        }
    
    def _execute_task(
        self,
        task_func: Callable,
        model_name: str,
        timeout_seconds: int,
        *args,
        **kwargs
    ) -> Dict:
        """ì‹¤ì œ ì‘ì—… ì‹¤í–‰"""
        
        try:
            # ëª¨ë¸ ì •ë³´ ì¶”ê°€
            model_data = self.registry["models"].get(model_name, {})
            kwargs["model"] = model_name
            kwargs["provider"] = model_data.get("provider")
            
            # í•¨ìˆ˜ ì‹¤í–‰
            start = time.time()
            result = task_func(*args, **kwargs)
            duration = time.time() - start
            
            # íƒ€ì„ì•„ì›ƒ ì²´í¬
            if duration > timeout_seconds:
                return {
                    "status": ExecutionStatus.TIMEOUT.value,
                    "error": f"íƒ€ì„ì•„ì›ƒ ({duration:.2f}s > {timeout_seconds}s)",
                    "result": result,
                    "tokens_used": 0
                }
            
            # ì„±ê³µ
            return {
                "status": ExecutionStatus.SUCCESS.value,
                "result": result,
                "tokens_used": kwargs.get("tokens_used", 0)
            }
        
        except Exception as e:
            return {
                "status": ExecutionStatus.FAILURE.value,
                "error": str(e),
                "result": None,
                "tokens_used": 0
            }
    
    def _evaluate_result(self, execution_result: Dict) -> int:
        """ê²°ê³¼ í‰ê°€ (0-100 ì ìˆ˜)"""
        
        status = execution_result["status"]
        
        if status == ExecutionStatus.SUCCESS.value:
            return 100
        elif status == ExecutionStatus.PARTIAL.value:
            return 50
        elif status == ExecutionStatus.FAILURE.value:
            return 0
        elif status == ExecutionStatus.API_ERROR.value:
            return -10
        elif status == ExecutionStatus.TIMEOUT.value:
            return 25
        else:
            return 50
    
    def _update_model_score(
        self,
        model_name: str,
        neural_level: str,
        status: str,
        quality_score: int,
        tokens_used: int,
        response_time_ms: int
    ):
        """ëª¨ë¸ ì ìˆ˜ ì—…ë°ì´íŠ¸"""
        
        if model_name not in self.registry["models"]:
            return
        
        # í•™ìŠµë¥  ì„¤ì •
        learning_rates = {
            ExecutionStatus.SUCCESS.value: 0.8,
            ExecutionStatus.PARTIAL.value: 0.9,
            ExecutionStatus.FAILURE.value: 0.5,
            ExecutionStatus.API_ERROR.value: 0.3,
            ExecutionStatus.TIMEOUT.value: 0.4
        }
        
        learning_rate = learning_rates.get(status, 0.5)
        
        # ì ìˆ˜ ê³„ì‚°
        old_score = self.registry["models"][model_name]["levels"][neural_level]["score"]
        new_score = (old_score * learning_rate) + (quality_score * (1 - learning_rate))
        
        # ìƒˆë¡œìš´ ì ìˆ˜ ì €ì¥
        self.registry["models"][model_name]["levels"][neural_level]["score"] = new_score
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        stats = self.registry["models"][model_name]["stats"]
        stats["total_calls"] += 1
        if status == ExecutionStatus.SUCCESS.value:
            stats["success_count"] += 1
        else:
            stats["failure_count"] += 1
        
        # í† í° ì‚¬ìš© ì¶”ì 
        self.registry["models"][model_name]["daily_tokens"]["used"] += tokens_used
        
        # ì €ì¥
        self._save_registry()
    
    def _get_response_percentile(self, model_name: str, response_time_ms: int) -> str:
        """ì‘ë‹µì‹œê°„ ë°±ë¶„ìœ„"""
        
        # ì¼ë°˜ì ì¸ ë²”ìœ„ (ms)
        if response_time_ms < 100:
            return "P99"  # ë§¤ìš° ë¹ ë¦„
        elif response_time_ms < 500:
            return "P95"  # ë¹ ë¦„
        elif response_time_ms < 1000:
            return "P75"  # í‰ê· 
        elif response_time_ms < 2000:
            return "P50"  # ëŠë¦¼
        else:
            return "P10"  # ë§¤ìš° ëŠë¦¼
    
    def _save_registry(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥"""
        self.registry["last_updated"] = datetime.now().isoformat()
        with open(self.registry_path, "w", encoding="utf-8") as f:
            json.dump(self.registry, f, indent=2, ensure_ascii=False)
    
    def _save_execution_log(self):
        """ì‹¤í–‰ ë¡œê·¸ ì €ì¥"""
        with open(self.execution_log_path, "w", encoding="utf-8") as f:
            json.dump(self.execution_log, f, indent=2, ensure_ascii=False)
    
    def get_execution_summary(self) -> Dict:
        """ì‹¤í–‰ ìš”ì•½"""
        
        logs = self.execution_log["executions"]
        
        if not logs:
            return {"total": 0}
        
        total = len(logs)
        success = sum(1 for l in logs if l["status"] == ExecutionStatus.SUCCESS.value)
        avg_quality = sum(l.get("quality_score", 0) for l in logs) / total if total > 0 else 0
        avg_duration = sum(l.get("duration_ms", 0) for l in logs) / total if total > 0 else 0
        
        return {
            "total_executions": total,
            "success_count": success,
            "success_rate": round(success / total * 100, 1) if total > 0 else 0,
            "avg_quality_score": round(avg_quality, 1),
            "avg_duration_ms": round(avg_duration, 0),
            "timestamp": datetime.now().isoformat()
        }


# í…ŒìŠ¤íŠ¸ìš© í•¨ìˆ˜
def sample_task(model=None, provider=None, tokens_used=100, **kwargs) -> Dict:
    """ìƒ˜í”Œ ì‘ì—…"""
    return {
        "result": f"ì‘ì—… ì™„ë£Œ ({model})",
        "tokens_used": tokens_used
    }


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    executor = NeuralExecutor()
    
    print("ğŸ§  ì‹ ê²½ ì‹¤í–‰ì í…ŒìŠ¤íŠ¸\n")
    
    # í…ŒìŠ¤íŠ¸: L1 ë‡Œê°„ ì‘ì—… (ë¹ ë¥¸ ì§„ë‹¨)
    result1 = executor.execute_with_neural_routing(
        task_id="task_001",
        task_name="ë¹ ë¥¸ ì§„ë‹¨",
        neural_level="L1",
        task_func=sample_task,
        tokens_used=50
    )
    
    print(f"âœ… {result1['task_name']}")
    print(f"   ëª¨ë¸: {result1['model']}")
    print(f"   ìƒíƒœ: {result1['status']}")
    print(f"   ì‹œê°„: {result1['duration_ms']}ms\n")
    
    # ìš”ì•½
    summary = executor.get_execution_summary()
    print(f"ğŸ“Š ì‹¤í–‰ ìš”ì•½")
    print(f"   ì´ ì‹¤í–‰: {summary['total_executions']}")
    print(f"   ì„±ê³µë¥ : {summary['success_rate']}%")
    print(f"   í‰ê·  ì ìˆ˜: {summary['avg_quality_score']}/100")
