"""
ğŸ“Š ì‘ì—… ì¶”ì ê¸° (Work Tracker)
ì‹ ê²½ê³„ ê¸°ë°˜ ì‘ì—… ì‹¤í–‰ ë° íš¨ìœ¨ì„± ì¶”ì 

ì—­í• : ì‘ì—… ì‹œì‘ â†’ ì‹ ê²½ê³„ í• ë‹¹ â†’ ì‘ì—… ì‹¤í–‰ â†’ íš¨ìœ¨ì„± ë¦¬í¬íŠ¸
íŠ¹ì§•: ìë™ ì‹ ê²½ê³„ í™œì„±í™”, ì‹¤ì‹œê°„ ì¶”ì , ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
"""

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional
from neural_router import NeuralModelRouter
import json


class WorkTracker:
    """ì‹ ê²½ê³„ ê¸°ë°˜ ì‘ì—… ì¶”ì  ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.router = NeuralModelRouter()
        self.current_work = None
        self.work_history = []
    
    def start_work(
        self,
        task_name: str,
        neural_levels: List[str],
        description: str = ""
    ) -> Dict:
        """
        ì‘ì—… ì‹œì‘ - ì‹ ê²½ê³„ í• ë‹¹ ë° ì¶”ì  ì‹œì‘
        
        Args:
            task_name: ì‘ì—…ëª…
            neural_levels: í•„ìš”í•œ ì‹ ê²½ê³„ ë ˆë²¨ (ì˜ˆ: ["L1", "L2", "L3", "L4"])
            description: ì‘ì—… ì„¤ëª…
        
        Returns:
            {
                "task_id": "WORK_2026020117590001",
                "task_name": "Workspace ì •ë¦¬",
                "start_time": "2026-02-01T17:59:00Z",
                "neural_levels": ["L1", "L2", "L3", "L4"],
                "allocations": {...}
            }
        """
        
        # ì‘ì—… ID ìƒì„±
        timestamp = datetime.now().strftime("%Y%m%d%H%M%S%f")[:14]
        task_id = f"WORK_{timestamp}"
        
        # ì‹ ê²½ê³„ í• ë‹¹
        report = self.router.get_neural_allocation_report(task_name, neural_levels)
        
        # ì‘ì—… ì •ë³´ ì €ì¥
        self.current_work = {
            "task_id": task_id,
            "task_name": task_name,
            "description": description,
            "start_time": datetime.now().isoformat(),
            "neural_levels": neural_levels,
            "allocations": report["allocations"],
            "efficiency_target": report["total_efficiency"],
            "status": "in_progress",
            "steps": []
        }
        
        # ì½˜ì†” ì¶œë ¥
        print(f"\nğŸš€ ì‘ì—… ì‹œì‘: {task_name}")
        print(f"ğŸ“‹ ì‘ì—… ID: {task_id}")
        print(f"â±ï¸  ì‹œì‘: {self.current_work['start_time']}")
        print(f"ğŸ§  ì‹ ê²½ê³„ ë ˆë²¨: {neural_levels}")
        print(f"â­ ëª©í‘œ íš¨ìœ¨: {report['total_efficiency']:.1f}/10")
        print("\nì‹ ê²½ê³„ í• ë‹¹:")
        
        for level, alloc in report["allocations"].items():
            if "primary" in alloc:
                print(f"  {level}: {alloc['primary']} ({alloc['score']:.1f}%)")
        
        print()
        
        return {
            "task_id": task_id,
            "status": "started",
            "allocations": report["allocations"]
        }
    
    def log_step(
        self,
        step_name: str,
        neural_level: str,
        model: str,
        status: str,
        quality_score: int = 100,
        response_time_ms: int = 0,
        tokens_used: int = 0
    ) -> Dict:
        """
        ì‘ì—… ì§„í–‰ ë‹¨ê³„ ê¸°ë¡
        
        Args:
            step_name: ë‹¨ê³„ëª…
            neural_level: ì‚¬ìš©í•œ ì‹ ê²½ê³„ ë ˆë²¨
            model: ì‚¬ìš©í•œ ëª¨ë¸
            status: "success" | "partial" | "failure" | "api_error"
            quality_score: 0-100
            response_time_ms: ì‘ë‹µ ì‹œê°„
            tokens_used: í† í° ì‚¬ìš©ëŸ‰
        
        Returns:
            ì—…ë°ì´íŠ¸ ê²°ê³¼
        """
        
        if not self.current_work:
            return {"error": "ì‘ì—…ì„ ë¨¼ì € ì‹œì‘í•´ì£¼ì„¸ìš”"}
        
        # ë‹¨ê³„ ê¸°ë¡
        step = {
            "step_name": step_name,
            "neural_level": neural_level,
            "model": model,
            "status": status,
            "quality_score": quality_score,
            "response_time_ms": response_time_ms,
            "tokens_used": tokens_used,
            "timestamp": datetime.now().isoformat()
        }
        
        self.current_work["steps"].append(step)
        
        # ëª¨ë¸ ì ìˆ˜ ì—…ë°ì´íŠ¸
        update_result = self.router.update_score(
            neural_level,
            model,
            {
                "status": status,
                "quality_score": quality_score,
                "response_time_ms": response_time_ms,
                "tokens_used": tokens_used
            }
        )
        
        # ì½˜ì†” ì¶œë ¥
        status_icon = {
            "success": "âœ…",
            "partial": "âš ï¸ ",
            "failure": "âŒ",
            "api_error": "ğŸ”´"
        }.get(status, "â“")
        
        print(f"{status_icon} {step_name}")
        print(f"   ëª¨ë¸: {model} ({neural_level})")
        print(f"   ì ìˆ˜: {update_result['old_score']:.1f} â†’ {update_result['new_score']:.1f} ({update_result['change']})")
        print(f"   ì‘ë‹µ: {response_time_ms}ms | í’ˆì§ˆ: {quality_score}%")
        print()
        
        return update_result
    
    def end_work(self, final_status: str = "completed") -> Dict:
        """
        ì‘ì—… ì™„ë£Œ - ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            final_status: "completed" | "failed" | "cancelled"
        
        Returns:
            ìµœì¢… ë¦¬í¬íŠ¸
        """
        
        if not self.current_work:
            return {"error": "í™œì„± ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤"}
        
        # ì†Œìš” ì‹œê°„ ê³„ì‚°
        start_time = datetime.fromisoformat(self.current_work["start_time"])
        end_time = datetime.now()
        duration_seconds = (end_time - start_time).total_seconds()
        
        # íš¨ìœ¨ì„± ê³„ì‚°
        step_scores = [s.get("quality_score", 100) for s in self.current_work["steps"]]
        avg_quality = sum(step_scores) / len(step_scores) if step_scores else 100
        actual_efficiency = (avg_quality / 100) * 10
        
        # í† í° ì‚¬ìš© ê³„ì‚°
        total_tokens = sum(s.get("tokens_used", 0) for s in self.current_work["steps"])
        
        # ìµœì¢… ë¦¬í¬íŠ¸
        report = {
            "task_id": self.current_work["task_id"],
            "task_name": self.current_work["task_name"],
            "status": final_status,
            "start_time": self.current_work["start_time"],
            "end_time": end_time.isoformat(),
            "duration_seconds": duration_seconds,
            "neural_levels": self.current_work["neural_levels"],
            "steps_executed": len(self.current_work["steps"]),
            "efficiency": {
                "target": self.current_work["efficiency_target"],
                "actual": round(actual_efficiency, 1),
                "variance": round(actual_efficiency - self.current_work["efficiency_target"], 1)
            },
            "quality": {
                "average_score": round(avg_quality, 1),
                "success_rate": sum(1 for s in self.current_work["steps"] if s["status"] == "success") / len(self.current_work["steps"]) if self.current_work["steps"] else 0
            },
            "resources": {
                "total_tokens": total_tokens,
                "avg_response_time_ms": round(sum(s.get("response_time_ms", 0) for s in self.current_work["steps"]) / len(self.current_work["steps"]), 0) if self.current_work["steps"] else 0
            },
            "allocations": self.current_work["allocations"]
        }
        
        # íˆìŠ¤í† ë¦¬ì— ì¶”ê°€
        self.work_history.append(report)
        
        # ì½˜ì†” ì¶œë ¥
        print(f"\n{'='*60}")
        print(f"âœ… ì‘ì—… ì™„ë£Œ: {self.current_work['task_name']}")
        print(f"{'='*60}")
        print(f"ì‘ì—… ID: {report['task_id']}")
        print(f"ìƒíƒœ: {final_status.upper()}")
        print(f"â±ï¸  ì†Œìš”ì‹œê°„: {duration_seconds:.1f}ì´ˆ")
        print(f"\nğŸ“Š íš¨ìœ¨ì„±:")
        print(f"  ëª©í‘œ: {report['efficiency']['target']:.1f}/10")
        print(f"  ì‹¤ì œ: {report['efficiency']['actual']:.1f}/10")
        print(f"  í¸ì°¨: {report['efficiency']['variance']:+.1f}")
        print(f"\nğŸ“ˆ í’ˆì§ˆ:")
        print(f"  í‰ê·  ì ìˆ˜: {report['quality']['average_score']:.1f}%")
        print(f"  ì„±ê³µë¥ : {report['quality']['success_rate']*100:.1f}%")
        print(f"\nğŸ’¾ ë¦¬ì†ŒìŠ¤:")
        print(f"  ì‚¬ìš© í† í°: {report['resources']['total_tokens']}")
        print(f"  í‰ê·  ì‘ë‹µ: {report['resources']['avg_response_time_ms']:.0f}ms")
        print(f"{'='*60}\n")
        
        # ì‘ì—… ì´ˆê¸°í™”
        self.current_work = None
        
        return report
    
    def get_work_history(self, limit: int = 10) -> List[Dict]:
        """ìµœê·¼ ì‘ì—… íˆìŠ¤í† ë¦¬ ì¡°íšŒ"""
        return self.work_history[-limit:]
    
    def save_report(self, report: Dict, filename: Optional[str] = None):
        """ë¦¬í¬íŠ¸ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        if filename is None:
            filename = f"work_report_{report['task_id']}.json"
        
        filepath = Path(__file__).parent / "reports" / filename
        filepath.parent.mkdir(parents=True, exist_ok=True)
        
        with open(filepath, "w", encoding="utf-8") as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return {"saved": True, "path": str(filepath)}


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    tracker = WorkTracker()
    
    # 1. ì‘ì—… ì‹œì‘
    tracker.start_work(
        task_name="Workspace ì •ë¦¬",
        neural_levels=["L1", "L2", "L3", "L4"],
        description="GitHub ì €ì¥ì†Œì™€ Workspace ë™ê¸°í™”"
    )
    
    # 2. ë‹¨ê³„ë³„ ì§„í–‰
    tracker.log_step(
        step_name="GitHub ìƒíƒœ ì§„ë‹¨",
        neural_level="L1",
        model="Groq",
        status="success",
        quality_score=98,
        response_time_ms=230,
        tokens_used=1200
    )
    
    tracker.log_step(
        step_name="ìš°ì„ ìˆœìœ„ íŒë‹¨",
        neural_level="L2",
        model="Gemini",
        status="success",
        quality_score=95,
        response_time_ms=1200,
        tokens_used=3400
    )
    
    # 3. ì‘ì—… ì™„ë£Œ
    report = tracker.end_work(final_status="completed")
