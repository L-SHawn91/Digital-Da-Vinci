"""
ğŸ§  ì‹ ê²½ ë¼ìš°í„° (Neural Router)
D-CNS ì‹ ê²½ê³„ë³„ ìµœì  ëª¨ë¸ ìë™ ì„ íƒ ì‹œìŠ¤í…œ

ì—­í• : ì‘ì—…ì˜ ì‹ ê²½ê³„ ë ˆë²¨ì— ë”°ë¼ ìµœì ì˜ ëª¨ë¸ì„ ë™ì ìœ¼ë¡œ ì„ íƒ
íŠ¹ì§•: ì‹¤ì‹œê°„ í† í° ì¶”ì , ê°•í™”í•™ìŠµ ê¸°ë°˜ ì ìˆ˜ ì—…ë°ì´íŠ¸
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional


class NeuralModelRouter:
    """ì‹ ê²½ê³„ ê¸°ë°˜ ì§€ëŠ¥í˜• ëª¨ë¸ ë¼ìš°í„°"""
    
    def __init__(self):
        self.registry_path = Path(__file__).parent / "neural_model_registry.json"
        self.registry = self._load_registry()
    
    def select_model(self, neural_level: str, task_type: str = "general") -> Dict:
        """
        ì‹ ê²½ê³„ ë ˆë²¨ì— ë”°ë¼ ìµœì  ëª¨ë¸ ì„ íƒ
        
        Args:
            neural_level: "L1" | "L2" | "L3" | "L4"
            task_type: ì‘ì—… ìœ í˜• (ì¼ë°˜)
        
        Returns:
            {
                "primary": "Groq",
                "score": 92.3,
                "level": "L1",
                "neurotransmitter": "ë…¸ë¥´ì—í”¼ë„¤í”„ë¦°",
                "alternatives": [("DeepSeek", 85.7), ...],
                "reason": "ë¹ ë¥¸ ì§„ë‹¨ í•„ìš”"
            }
        """
        
        if neural_level not in ["L1", "L2", "L3", "L4"]:
            return {"error": f"Invalid neural level: {neural_level}"}
        
        # 1. ì‹ ê²½ê³„ë³„ ê°€ì¤‘ì¹˜ë¡œ ì ìˆ˜ ì¬ê³„ì‚°
        scores = {}
        for model_name, model_data in self.registry["models"].items():
            if neural_level in model_data["levels"]:
                level_score = model_data["levels"][neural_level]["score"]
                
                # í† í° ê°€ìš©ì„± í™•ì¸
                tokens = model_data["daily_tokens"]
                token_availability = tokens["used"] / tokens["limit"]
                
                # í† í° 90% ì´ìƒ ì‚¬ìš© ì‹œ ì œì™¸
                if token_availability >= 0.90:
                    continue
                
                scores[model_name] = {
                    "score": level_score,
                    "neurotransmitter": model_data["neurotransmitter"],
                    "token_available": tokens["limit"] - tokens["used"]
                }
        
        if not scores:
            return {
                "error": "ëª¨ë“  ëª¨ë¸ í† í° ë¶€ì¡±",
                "fallback": "Groq",
                "recommendation": "í† í° ë¦¬ì…‹ ëŒ€ê¸°"
            }
        
        # 2. ìµœì  ëª¨ë¸ ì„ íƒ
        best_model = max(scores.items(), key=lambda x: x[1]["score"])
        
        # 3. ëŒ€ì²´ ëª¨ë¸ ëª©ë¡
        alternatives = sorted(
            [(name, data["score"]) for name, data in scores.items()],
            key=lambda x: x[1],
            reverse=True
        )[1:]
        
        return {
            "primary": best_model[0],
            "score": best_model[1]["score"],
            "neurotransmitter": best_model[1]["neurotransmitter"],
            "level": neural_level,
            "task_type": task_type,
            "alternatives": alternatives,
            "reason": self._explain_choice(neural_level, best_model[0]),
            "token_remaining": best_model[1]["token_available"]
        }
    
    def update_score(
        self,
        neural_level: str,
        model: str,
        result: Dict
    ) -> Dict:
        """
        ê°•í™”í•™ìŠµìœ¼ë¡œ ëª¨ë¸ ì ìˆ˜ ì—…ë°ì´íŠ¸
        
        Args:
            neural_level: "L1" | "L2" | "L3" | "L4"
            model: ëª¨ë¸ëª…
            result: {
                "status": "success" | "partial" | "failure" | "api_error",
                "quality_score": 0-100 (optional),
                "response_time_ms": 123,
                "tokens_used": 456
            }
        
        Returns:
            {
                "model": "Groq",
                "level": "L1",
                "old_score": 92.3,
                "new_score": 93.1,
                "change": "+0.8"
            }
        """
        
        if model not in self.registry["models"]:
            return {"error": f"Unknown model: {model}"}
        
        # 1. ì„±ê³µë„ íŒì •
        status = result.get("status", "unknown")
        
        if status == "success":
            quality = result.get("quality_score", 100)
            learning_rate = 0.8
            bonus = 10
        elif status == "partial":
            quality = 50
            learning_rate = 0.9
            bonus = 0
        elif status == "failure":
            quality = 0
            learning_rate = 0.5
            bonus = -20
        elif status == "api_error":
            quality = -10
            learning_rate = 0.3
            bonus = -30
        else:
            quality = 25
            learning_rate = 0.7
            bonus = 0
        
        # 2. ì ìˆ˜ ê³„ì‚° (ê°•í™”í•™ìŠµ)
        old_score = self.registry["models"][model]["levels"][neural_level]["score"]
        new_score = (old_score * learning_rate) + (quality * (1 - learning_rate)) + bonus
        new_score = max(0, min(100, new_score))
        
        # 3. ì ìˆ˜ ì—…ë°ì´íŠ¸
        self.registry["models"][model]["levels"][neural_level]["score"] = new_score
        
        # 4. í†µê³„ ì—…ë°ì´íŠ¸
        self.registry["models"][model]["stats"]["total_calls"] += 1
        if status == "success":
            self.registry["models"][model]["stats"]["success_count"] += 1
        else:
            self.registry["models"][model]["stats"]["failure_count"] += 1
        
        self.registry["models"][model]["stats"]["last_success"] = datetime.now().isoformat()
        
        # 5. í† í° ì‚¬ìš©ëŸ‰ ì—…ë°ì´íŠ¸
        tokens_used = result.get("tokens_used", 0)
        self.registry["models"][model]["daily_tokens"]["used"] += tokens_used
        
        # 6. ì €ì¥
        self._save_registry()
        
        change = new_score - old_score
        
        return {
            "model": model,
            "level": neural_level,
            "status": status,
            "old_score": round(old_score, 1),
            "new_score": round(new_score, 1),
            "change": f"{change:+.1f}",
            "learning_rate": learning_rate,
            "tokens_used": tokens_used,
            "total_tokens_used": self.registry["models"][model]["daily_tokens"]["used"]
        }
    
    def get_neural_allocation_report(self, task_name: str, neural_levels: List[str]) -> Dict:
        """
        ì‘ì—…ì˜ ì‹ ê²½ê³„ í• ë‹¹ ë¦¬í¬íŠ¸ ìƒì„±
        
        Args:
            task_name: ì‘ì—… ì´ë¦„
            neural_levels: ì‚¬ìš©í•  ì‹ ê²½ê³„ ë ˆë²¨ ëª©ë¡
        
        Returns:
            {
                "task": "ì‘ì—…ëª…",
                "neural_levels": ["L1", "L2", ...],
                "allocations": {
                    "L1": {"primary": "Groq", "score": 92.3, ...},
                    ...
                },
                "total_efficiency": 9.5,
                "estimated_cost": 0.015
            }
        """
        
        allocations = {}
        scores = []
        
        for level in neural_levels:
            allocation = self.select_model(level)
            allocations[level] = allocation
            if "score" in allocation:
                scores.append(allocation["score"])
        
        avg_efficiency = sum(scores) / len(scores) if scores else 0
        total_efficiency = (avg_efficiency / 100) * 10  # 10ì  ë§Œì 
        
        return {
            "task": task_name,
            "neural_levels": neural_levels,
            "allocations": allocations,
            "total_efficiency": round(total_efficiency, 1),
            "estimated_cost": round(len(neural_levels) * 0.01, 4),
            "timestamp": datetime.now().isoformat()
        }
    
    def _explain_choice(self, neural_level: str, model: str) -> str:
        """ëª¨ë¸ ì„ íƒ ì´ìœ  ì„¤ëª…"""
        
        reasons = {
            "L1": "ë¹ ë¥¸ ì§„ë‹¨ í•„ìš”",
            "L2": "ì •í™•í•œ ìš°ì„ ìˆœìœ„ íŒë‹¨",
            "L3": "ë³µì¡í•œ ë¶„ì„ & ì°½ì˜ì„±",
            "L4": "ë¼ìš°íŒ… & ìµœì í™”"
        }
        
        return f"{reasons.get(neural_level, 'ì‘ì—… ì‹¤í–‰')} - {model}"
    
    def _load_registry(self) -> Dict:
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ë¡œë“œ"""
        try:
            with open(self.registry_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            return {"models": {}, "version": "2.0"}
    
    def _save_registry(self):
        """ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì €ì¥"""
        self.registry["last_updated"] = datetime.now().isoformat()
        with open(self.registry_path, "w", encoding="utf-8") as f:
            json.dump(self.registry, f, indent=2, ensure_ascii=False)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    router = NeuralModelRouter()
    
    # 1. ì‹ ê²½ê³„ë³„ ëª¨ë¸ ì„ íƒ
    print("ğŸ§  L1 ë‡Œê°„ - ë¹ ë¥¸ ì§„ë‹¨")
    result_l1 = router.select_model("L1")
    print(f"ì„ íƒ: {result_l1['primary']} ({result_l1['score']:.1f}%)\n")
    
    # 2. ì‘ì—… í• ë‹¹ ë¦¬í¬íŠ¸
    print("ğŸ“‹ ì‘ì—… ì‹ ê²½ê³„ í• ë‹¹")
    report = router.get_neural_allocation_report(
        "Workspace ì •ë¦¬",
        ["L1", "L2", "L3", "L4"]
    )
    print(f"ì‘ì—…: {report['task']}")
    print(f"ì „ì²´ íš¨ìœ¨: {report['total_efficiency']}/10")
    print(f"ì˜ˆìƒ ë¹„ìš©: ${report['estimated_cost']}")
