"""
# neural_efficiency_tracker.py - ì‹ ê²½ê³„ íš¨ìœ¨ ì¶”ì  ì‹œìŠ¤í…œ

ì‹ ê²½ê³„ë³„, ëª¨ë¸ë³„ íš¨ìœ¨ì„±ì„ ë§¤ë²ˆ ì²´í¬í•˜ê³  ê¸°ë¡í•˜ëŠ” ì‹œìŠ¤í…œ

ìš©ë„:
  â”œâ”€ ê° ì‹ ê²½ê³„(L1-L4)ê°€ ì–´ë–¤ ëª¨ë¸ì„ ì‚¬ìš©í–ˆëŠ”ì§€ ì¶”ì 
  â”œâ”€ ê° ëª¨ë¸ì˜ íš¨ìœ¨ ì ìˆ˜ (0-10)
  â”œâ”€ ì‹ ê²½ê³„ë³„ ê¸°ì—¬ë„ ì¸¡ì •
  â”œâ”€ ì‹œê°„ ê²½ê³¼ì— ë”°ë¥¸ íš¨ìœ¨ ê°œì„  ì¶”ì 
  â””â”€ ë§ˆì¼ìŠ¤í†¤ ë‹¬ì„± ì‹œ ì„±ê³¼ ê²€ì¦

êµ¬ì¡°:
  â”œâ”€ NeuralLevel (L1-L4 ì •ì˜)
  â”œâ”€ ModelInfo (ëª¨ë¸ ì •ë³´)
  â”œâ”€ EfficiencyMetric (íš¨ìœ¨ ì¸¡ì •)
  â”œâ”€ NeuralTask (ê°œë³„ ì‘ì—… ì¶”ì )
  â””â”€ NeuralEfficiencyTracker (í†µí•© ì¶”ì )
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Optional, Tuple
from dataclasses import dataclass, asdict, field
from enum import Enum
from pathlib import Path


# ============================================================================
# 1. ì‹ ê²½ê³„ ì •ì˜
# ============================================================================

class NeuralLevel(Enum):
    """ì‹ ê²½ê³„ ê³„ì¸µ"""
    L1_BRAINSTEM = ("L1_BRAINSTEM", "ë‡Œê°„", "Adrenaline")
    L2_LIMBIC = ("L2_LIMBIC", "ë³€ì—°ê³„", "Serotonin")
    L3_NEOCORTEX = ("L3_NEOCORTEX", "ì‹ í”¼ì§ˆ", "Acetylcholine")
    L4_NEURONET = ("L4_NEURONET", "ì‹ ê²½ë§", "Dopamine")
    
    def __init__(self, code: str, korean: str, neurotransmitter: str):
        self.code = code
        self.korean = korean
        self.neurotransmitter = neurotransmitter


# ============================================================================
# 2. ëª¨ë¸ ì •ë³´
# ============================================================================

@dataclass
class ModelInfo:
    """ëª¨ë¸ ì •ë³´"""
    model_id: str                    # "groq", "gemini", "claude", etc
    model_name: str                  # "Groq Llama 3.1"
    provider: str                    # "Groq", "Google", "Anthropic"
    category: str                    # "coding", "analysis", "general", "creative"
    cost_per_1k_tokens: float        # $
    speed_ms_per_1k_tokens: float    # ms
    quality_score_out_of_10: float   # 0-10 baseline


@dataclass
class EfficiencyMetric:
    """íš¨ìœ¨ ì¸¡ì •"""
    neural_level: NeuralLevel
    model_used: ModelInfo
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    # ì…ë ¥
    task_description: str = ""
    input_tokens: int = 0
    
    # ì¶œë ¥
    output_tokens: int = 0
    response_time_ms: int = 0
    success: bool = True
    error_message: str = ""
    
    # íš¨ìœ¨ ì ìˆ˜ (0-10)
    efficiency_score: float = 0.0      # ì†ë„ ê¸°ë°˜
    quality_score: float = 0.0         # ê²°ê³¼ í’ˆì§ˆ
    cost_efficiency_score: float = 0.0 # ë¹„ìš© íš¨ìœ¨
    overall_score: float = 0.0         # ì¢…í•© (0-10)
    
    def calculate_scores(self, target_response_time_ms: int = 3000):
        """íš¨ìœ¨ ì ìˆ˜ ê³„ì‚°"""
        if not self.success:
            self.efficiency_score = 0.0
            self.quality_score = 0.0
            self.cost_efficiency_score = 0.0
            self.overall_score = 0.0
            return
        
        # 1. íš¨ìœ¨ì„± ì ìˆ˜ (ì†ë„ ê¸°ë°˜) - 0-10
        # ëª©í‘œ: target_response_time_ms ì´ë‚´
        efficiency_ratio = min(1.0, target_response_time_ms / self.response_time_ms)
        self.efficiency_score = efficiency_ratio * 10.0
        
        # 2. í’ˆì§ˆ ì ìˆ˜ - ëª¨ë¸ì˜ baseline + ì¡°ì •
        # (ì‹¤ì œë¡œëŠ” LLM íŒì •ì´ í•„ìš”í•˜ì§€ë§Œ, ì—¬ê¸°ì„  baseline ì‚¬ìš©)
        self.quality_score = self.model_used.quality_score_out_of_10
        
        # 3. ë¹„ìš© íš¨ìœ¨ ì ìˆ˜ - 0-10
        # ë” ì €ë ´í• ìˆ˜ë¡ ë†’ì€ ì ìˆ˜
        total_cost = (self.input_tokens + self.output_tokens) / 1000 * self.model_used.cost_per_1k_tokens
        
        # $0.001 = 10ì , $0.1 = 0ì  (ë¡œê·¸ ìŠ¤ì¼€ì¼)
        if total_cost <= 0.001:
            cost_efficiency = 10.0
        elif total_cost >= 0.1:
            cost_efficiency = 0.0
        else:
            # ë¡œê·¸ ìŠ¤ì¼€ì¼: ln(0.1/total_cost) / ln(100)
            import math
            cost_efficiency = min(10.0, max(0.0, 
                (math.log(0.1 / total_cost) / math.log(100)) * 10.0
            ))
        
        self.cost_efficiency_score = cost_efficiency
        
        # 4. ì¢…í•© ì ìˆ˜ (0-10)
        # efficiency(3) + quality(4) + cost_efficiency(3)
        self.overall_score = (
            self.efficiency_score * 0.3 +
            self.quality_score * 0.4 +
            self.cost_efficiency_score * 0.3
        )
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'timestamp': self.timestamp,
            'neural_level': self.neural_level.code,
            'model': self.model_used.model_id,
            'model_name': self.model_used.model_name,
            'task': self.task_description,
            'tokens': {
                'input': self.input_tokens,
                'output': self.output_tokens,
                'total': self.input_tokens + self.output_tokens
            },
            'timing': {
                'response_time_ms': self.response_time_ms,
                'speed_per_1k_tokens_ms': (
                    self.response_time_ms / ((self.input_tokens + self.output_tokens) / 1000)
                    if (self.input_tokens + self.output_tokens) > 0 else 0
                )
            },
            'cost': {
                'total_cost_usd': (
                    (self.input_tokens + self.output_tokens) / 1000 *
                    self.model_used.cost_per_1k_tokens
                ),
                'cost_per_1k_tokens_usd': self.model_used.cost_per_1k_tokens
            },
            'scores': {
                'efficiency': round(self.efficiency_score, 2),      # ì†ë„
                'quality': round(self.quality_score, 2),            # í’ˆì§ˆ
                'cost_efficiency': round(self.cost_efficiency_score, 2),  # ë¹„ìš©
                'overall': round(self.overall_score, 2)             # ì¢…í•©
            },
            'success': self.success,
            'error': self.error_message if not self.success else None
        }


# ============================================================================
# 3. ì‹ ê²½ê³„ ì‘ì—… ì¶”ì 
# ============================================================================

@dataclass
class NeuralTask:
    """ê°œë³„ ì‘ì—…"""
    task_id: str
    neural_level: NeuralLevel
    timestamp: str = field(default_factory=lambda: datetime.now().isoformat())
    
    task_type: str = ""              # "analysis", "coding", "decision", etc
    description: str = ""
    
    metrics: List[EfficiencyMetric] = field(default_factory=list)
    
    def add_metric(self, metric: EfficiencyMetric):
        """ë©”íŠ¸ë¦­ ì¶”ê°€"""
        self.metrics.append(metric)
    
    def get_best_model(self) -> Optional[Tuple[str, float]]:
        """ê°€ì¥ ì¢‹ì€ ëª¨ë¸ ë°˜í™˜"""
        if not self.metrics:
            return None
        
        best_metric = max(self.metrics, key=lambda m: m.overall_score)
        return (best_metric.model_used.model_id, best_metric.overall_score)
    
    def get_average_score(self) -> float:
        """í‰ê·  ì ìˆ˜"""
        if not self.metrics:
            return 0.0
        
        return sum(m.overall_score for m in self.metrics) / len(self.metrics)
    
    def to_dict(self) -> Dict:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return {
            'task_id': self.task_id,
            'neural_level': self.neural_level.code,
            'neural_level_korean': self.neural_level.korean,
            'neurotransmitter': self.neural_level.neurotransmitter,
            'timestamp': self.timestamp,
            'task_type': self.task_type,
            'description': self.description,
            'metrics_count': len(self.metrics),
            'metrics': [m.to_dict() for m in self.metrics],
            'average_score': round(self.get_average_score(), 2),
            'best_model': self.get_best_model()
        }


# ============================================================================
# 4. ì‹ ê²½ê³„ íš¨ìœ¨ ì¶”ì  ì‹œìŠ¤í…œ
# ============================================================================

class NeuralEfficiencyTracker:
    """ì‹ ê²½ê³„ íš¨ìœ¨ í†µí•© ì¶”ì """
    
    def __init__(self, output_dir: str = "logs/neural_efficiency"):
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë¸ ì €ì¥ì†Œ
        self.models: Dict[str, ModelInfo] = {}
        self._init_models()
        
        # ì‘ì—… ì €ì¥ì†Œ
        self.tasks: Dict[str, NeuralTask] = {}
        
        # ì‹ ê²½ê³„ë³„ í†µê³„
        self.neural_stats: Dict[str, Dict] = {
            level.code: {
                'tasks': 0,
                'total_score': 0.0,
                'avg_score': 0.0,
                'best_score': 0.0,
                'models_used': {}
            }
            for level in NeuralLevel
        }
    
    def _init_models(self):
        """ëª¨ë¸ ì´ˆê¸°í™”"""
        models_config = [
            # L1 ë‡Œê°„ (ë¹ ë¥´ê³  ì €ë ´)
            ModelInfo("groq", "Groq Llama 3.1", "Groq", "general", 0.00005, 500, 7.5),
            ModelInfo("cerebras", "Cerebras", "Cerebras", "general", 0.000, 800, 7.0),
            
            # L2 ë³€ì—°ê³„ (ê· í˜•)
            ModelInfo("gemini", "Gemini 2.5 Pro", "Google", "analysis", 0.00075, 2300, 9.9),
            ModelInfo("groq-extended", "Groq Extended", "Groq", "analysis", 0.0001, 600, 8.5),
            
            # L3 ì‹ í”¼ì§ˆ (ê³ í’ˆì§ˆ, ëŠë¦¼)
            ModelInfo("claude", "Claude 3.5 Sonnet", "Anthropic", "coding", 0.003, 2100, 9.4),
            ModelInfo("openai", "GPT-4 Turbo", "OpenAI", "coding", 0.01, 2400, 9.5),
            
            # L4 ì‹ ê²½ë§ (ìµœê³  í’ˆì§ˆ)
            ModelInfo("deepseek", "DeepSeek R1", "DeepSeek", "analysis", 0.0014, 2000, 8.7),
            ModelInfo("openrouter", "OpenRouter Multi", "OpenRouter", "general", 0.002, 1800, 8.6),
        ]
        
        for model in models_config:
            self.models[model.model_id] = model
    
    def create_task(
        self,
        task_id: str,
        neural_level: NeuralLevel,
        task_type: str,
        description: str
    ) -> NeuralTask:
        """ì‘ì—… ìƒì„±"""
        task = NeuralTask(
            task_id=task_id,
            neural_level=neural_level,
            task_type=task_type,
            description=description
        )
        self.tasks[task_id] = task
        return task
    
    def add_metric(
        self,
        task_id: str,
        model_id: str,
        input_tokens: int,
        output_tokens: int,
        response_time_ms: int,
        success: bool = True,
        error_message: str = ""
    ) -> EfficiencyMetric:
        """ë©”íŠ¸ë¦­ ì¶”ê°€"""
        if task_id not in self.tasks:
            raise ValueError(f"Task {task_id} not found")
        
        if model_id not in self.models:
            raise ValueError(f"Model {model_id} not found")
        
        task = self.tasks[task_id]
        model = self.models[model_id]
        
        # ë©”íŠ¸ë¦­ ìƒì„±
        metric = EfficiencyMetric(
            neural_level=task.neural_level,
            model_used=model,
            task_description=task.description,
            input_tokens=input_tokens,
            output_tokens=output_tokens,
            response_time_ms=response_time_ms,
            success=success,
            error_message=error_message
        )
        
        # ì ìˆ˜ ê³„ì‚°
        metric.calculate_scores()
        
        # ì‘ì—…ì— ì¶”ê°€
        task.add_metric(metric)
        
        # ì‹ ê²½ê³„ í†µê³„ ì—…ë°ì´íŠ¸
        self._update_neural_stats(task.neural_level, metric, model_id)
        
        return metric
    
    def _update_neural_stats(self, neural_level: NeuralLevel, metric: EfficiencyMetric, model_id: str):
        """ì‹ ê²½ê³„ í†µê³„ ì—…ë°ì´íŠ¸"""
        stats = self.neural_stats[neural_level.code]
        
        stats['tasks'] += 1
        stats['total_score'] += metric.overall_score
        stats['avg_score'] = stats['total_score'] / stats['tasks']
        stats['best_score'] = max(stats['best_score'], metric.overall_score)
        
        # ëª¨ë¸ë³„ ì‚¬ìš© íšŸìˆ˜
        if model_id not in stats['models_used']:
            stats['models_used'][model_id] = {'count': 0, 'total_score': 0.0}
        
        stats['models_used'][model_id]['count'] += 1
        stats['models_used'][model_id]['total_score'] += metric.overall_score
    
    def generate_neural_report(self) -> Dict:
        """ì‹ ê²½ê³„ íš¨ìœ¨ ë¦¬í¬íŠ¸ ìƒì„±"""
        return {
            'timestamp': datetime.now().isoformat(),
            'total_tasks': len(self.tasks),
            'neural_levels': self.neural_stats,
            'tasks': {
                task_id: task.to_dict()
                for task_id, task in self.tasks.items()
            }
        }
    
    def save_report(self, filename: str = "neural_efficiency_report.json"):
        """ë¦¬í¬íŠ¸ ì €ì¥"""
        report = self.generate_neural_report()
        
        report_path = self.output_dir / filename
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2, ensure_ascii=False)
        
        return report_path
    
    def print_summary(self):
        """ìš”ì•½ ì¶œë ¥"""
        print("\n" + "="*80)
        print("ğŸ§  ì‹ ê²½ê³„ íš¨ìœ¨ ì¶”ì  ë¦¬í¬íŠ¸")
        print("="*80)
        
        for level in NeuralLevel:
            stats = self.neural_stats[level.code]
            
            print(f"\n{level.korean} ({level.code})")
            print(f"  ì‹ ê²½ì „ë‹¬ë¬¼ì§ˆ: {level.neurotransmitter}")
            print(f"  ì‘ì—… ìˆ˜: {stats['tasks']}")
            print(f"  í‰ê·  ì ìˆ˜: {stats['avg_score']:.2f}/10")
            print(f"  ìµœê³  ì ìˆ˜: {stats['best_score']:.2f}/10")
            
            if stats['models_used']:
                print(f"  ì‚¬ìš© ëª¨ë¸:")
                for model_id, model_stats in stats['models_used'].items():
                    model_name = self.models[model_id].model_name
                    avg = model_stats['total_score'] / model_stats['count']
                    print(f"    - {model_name}: {model_stats['count']}íšŒ, í‰ê·  {avg:.2f}/10")
        
        print("\n" + "="*80)


# ============================================================================
# 5. ì‚¬ìš© ì˜ˆì‹œ
# ============================================================================

if __name__ == "__main__":
    # ì¶”ì  ì‹œìŠ¤í…œ ì´ˆê¸°í™”
    tracker = NeuralEfficiencyTracker()
    
    # L1 ë‡Œê°„ ì‘ì—… ìƒì„±
    task1 = tracker.create_task(
        "watchdog_001",
        NeuralLevel.L1_BRAINSTEM,
        "monitoring",
        "í”„ë¡œì„¸ìŠ¤ ëª¨ë‹ˆí„°ë§ ë° ìë™ ë³µêµ¬"
    )
    
    # Groq ëª¨ë¸ ì‚¬ìš©
    tracker.add_metric(
        "watchdog_001",
        "groq",
        input_tokens=150,
        output_tokens=50,
        response_time_ms=800,
        success=True
    )
    
    # L2 ë³€ì—°ê³„ ì‘ì—…
    task2 = tracker.create_task(
        "analysis_001",
        NeuralLevel.L2_LIMBIC,
        "analysis",
        "ê°ì • ë¶„ì„ ë° ìš°ì„ ìˆœìœ„ ê²°ì •"
    )
    
    # Gemini ëª¨ë¸ ì‚¬ìš©
    tracker.add_metric(
        "analysis_001",
        "gemini",
        input_tokens=500,
        output_tokens=200,
        response_time_ms=2500,
        success=True
    )
    
    # L3 ì‹ í”¼ì§ˆ ì‘ì—…
    task3 = tracker.create_task(
        "coding_001",
        NeuralLevel.L3_NEOCORTEX,
        "coding",
        "ì½”ë“œ ìƒì„± ë° ìµœì í™”"
    )
    
    # Claude ëª¨ë¸ ì‚¬ìš©
    tracker.add_metric(
        "coding_001",
        "claude",
        input_tokens=1000,
        output_tokens=800,
        response_time_ms=2100,
        success=True
    )
    
    # ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥
    report_path = tracker.save_report()
    print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥ë¨: {report_path}")
    
    tracker.print_summary()
