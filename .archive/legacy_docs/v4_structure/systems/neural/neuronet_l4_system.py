"""
L4 ì‹ ê²½ë§ (NeuroNet) - ì‹ ê²½ ì‹ í˜¸ ë¼ìš°íŒ… & ìë™ ìµœì í™”

ì—­í• :
- L1+L2+L3 ëª¨ë“  ì‹ í˜¸ë¥¼ í†µí•©í•˜ê³  ë¼ìš°íŒ…
- ì‹ ê²½ê°€ì†Œì„±: ìë™ í•™ìŠµ & ì ì‘
- ìµœì í™”: ì‹¤ì‹œê°„ ì„±ëŠ¥ íŠœë‹
- ìë™ ì œì–´: ì—ëŸ¬ ê°ì§€ & ë³µêµ¬

ëª©í‘œ: 10/10 (ì™„ë²½í•œ ì‹ ê²½ ì‹œìŠ¤í…œ)
"""

import json
import time
from datetime import datetime
from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass
from enum import Enum
import logging
import random

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class NeuralSignalType(Enum):
    """ì‹ ê²½ ì‹ í˜¸ íƒ€ì…"""
    SENSORY = "sensory"      # ê°ê° ì‹ í˜¸ (ì…ë ¥)
    MOTOR = "motor"          # ìš´ë™ ì‹ í˜¸ (ì¶œë ¥)
    EMOTIONAL = "emotional"  # ê°ì • ì‹ í˜¸ (L2)
    COGNITIVE = "cognitive"  # ì¸ì§€ ì‹ í˜¸ (L3)
    REGULATORY = "regulatory"  # ì¡°ì ˆ ì‹ í˜¸ (í”¼ë“œë°±)


@dataclass
class NeuralSignal:
    """ì‹ ê²½ ì‹ í˜¸"""
    signal_type: NeuralSignalType
    source: str  # L1, L2, L3
    destination: str  # L1, L2, L3, Motor
    data: Dict
    strength: float  # 0-1
    timestamp: str = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.now().isoformat()


class NeuralRouter:
    """ì‹ ê²½ ì‹ í˜¸ ë¼ìš°í„°"""
    
    def __init__(self):
        self.routing_table = {}
        self.signal_history = []
        self.latency_records = {}
        self._initialize_routing()

    def _initialize_routing(self):
        """ë¼ìš°íŒ… í…Œì´ë¸” ì´ˆê¸°í™”"""
        # L2 ê°ì • ì‹ í˜¸ â†’ L3 ì‹ í”¼ì§ˆ
        self.routing_table["L2â†’L3"] = {
            "path": ["prefrontal", "temporal"],
            "priority": 0.9,
            "latency_ms": 5
        }
        
        # L3 ì¸ì§€ ì‹ í˜¸ â†’ L1 ë‡Œê°„ (í”¼ë“œë°±)
        self.routing_table["L3â†’L1"] = {
            "path": ["parietal", "brainstem"],
            "priority": 0.85,
            "latency_ms": 3
        }
        
        # L1+L2 â†’ ìš´ë™ ì‹ í˜¸
        self.routing_table["Motor"] = {
            "path": ["integration_hub", "motor_cortex"],
            "priority": 1.0,
            "latency_ms": 2
        }

    def route_signal(self, signal: NeuralSignal) -> Dict:
        """ì‹ ê²½ ì‹ í˜¸ ë¼ìš°íŒ…"""
        route_key = f"{signal.source}â†’{signal.destination}"
        
        # ë¼ìš°íŒ… ì •ë³´ ì¡°íšŒ
        route_info = self.routing_table.get(route_key, {})
        
        # ì‹¤ì œ ì „ì†¡ (ì‹œë®¬ë ˆì´ì…˜)
        latency = route_info.get("latency_ms", random.randint(1, 10))
        success = random.random() > 0.02  # 98% ì„±ê³µë¥ 
        
        result = {
            "signal_id": f"{signal.source}-{datetime.now().timestamp()}",
            "route": route_key,
            "path": route_info.get("path", []),
            "latency_ms": latency,
            "success": success,
            "strength": signal.strength,
            "timestamp": datetime.now().isoformat()
        }
        
        # íˆìŠ¤í† ë¦¬ ì €ì¥
        self.signal_history.append(result)
        
        # ë ˆì´í„´ì‹œ ê¸°ë¡
        if route_key not in self.latency_records:
            self.latency_records[route_key] = []
        self.latency_records[route_key].append(latency)
        
        return result

    def get_routing_efficiency(self) -> float:
        """ë¼ìš°íŒ… íš¨ìœ¨ì„±"""
        if not self.signal_history:
            return 0.0
        
        successful = sum(1 for s in self.signal_history if s["success"])
        return successful / len(self.signal_history)

    def get_average_latency(self, route_key: str) -> float:
        """í‰ê·  ë ˆì´í„´ì‹œ"""
        if route_key not in self.latency_records:
            return 0.0
        
        latencies = self.latency_records[route_key]
        return sum(latencies) / len(latencies)


class Neuroplasticity:
    """ì‹ ê²½ê°€ì†Œì„± - ìë™ í•™ìŠµ & ì ì‘"""
    
    def __init__(self):
        self.learning_weights = {}
        self.adaptation_history = []
        self.learning_rate = 0.1

    def adapt_to_input(self, input_text: str, actual_output: str, 
                      expected_output: str) -> Dict:
        """ì…ë ¥ì— ì ì‘"""
        
        # 1. ì˜¤ë¥˜ ê³„ì‚°
        is_correct = actual_output == expected_output
        error = 0.0 if is_correct else 1.0
        
        # 2. ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸
        updated_weights = self._update_weights(input_text, error)
        
        # 3. í•™ìŠµ ì‹ í˜¸ ìƒì„±
        learning_signal = self._generate_learning_signal(error)
        
        # 4. ì ì‘ ì ìˆ˜
        adaptation_score = self._calculate_adaptation_score(error)
        
        record = {
            "timestamp": datetime.now().isoformat(),
            "input": input_text[:30],
            "is_correct": is_correct,
            "error": error,
            "learning_signal": learning_signal,
            "adaptation_score": adaptation_score,
            "weights_updated": len(updated_weights)
        }
        
        self.adaptation_history.append(record)
        
        return record

    def _update_weights(self, input_text: str, error: float) -> Dict:
        """ê°€ì¤‘ì¹˜ ì—…ë°ì´íŠ¸ (ë¸íƒ€ í•™ìŠµ)"""
        # í‚¤ì›Œë“œ ê¸°ë°˜ ê°€ì¤‘ì¹˜
        keywords = input_text.lower().split()
        updated = {}
        
        for keyword in keywords[:5]:  # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œ
            old_weight = self.learning_weights.get(keyword, 0.5)
            # Delta rule: w = w + Î· * error * x
            new_weight = old_weight + self.learning_rate * error * random.random()
            new_weight = max(0.0, min(1.0, new_weight))  # 0-1 ì •ê·œí™”
            
            self.learning_weights[keyword] = new_weight
            updated[keyword] = new_weight
        
        return updated

    def _generate_learning_signal(self, error: float) -> float:
        """í•™ìŠµ ì‹ í˜¸ ìƒì„±"""
        # ì˜¤ë¥˜ê°€ í¬ë©´ í•™ìŠµ ì‹ í˜¸ ê°•í•¨
        return min(1.0, error * 2.0)

    def _calculate_adaptation_score(self, error: float) -> float:
        """ì ì‘ ì ìˆ˜"""
        # ì ì‘ì´ ì˜ ë˜ë©´ ì ìˆ˜ ë†’ìŒ
        return max(0.0, 1.0 - error)

    def get_average_adaptation(self) -> float:
        """í‰ê·  ì ì‘ ì ìˆ˜"""
        if not self.adaptation_history:
            return 0.5
        
        scores = [h["adaptation_score"] for h in self.adaptation_history]
        return sum(scores) / len(scores)


class NeuralOptimizer:
    """ì‹ ê²½ ìµœì í™” - ì‹¤ì‹œê°„ ì„±ëŠ¥ íŠœë‹"""
    
    def __init__(self):
        self.optimization_params = {
            "prefrontal_weight": 0.3,
            "temporal_weight": 0.25,
            "parietal_weight": 0.25,
            "occipital_weight": 0.2
        }
        self.optimization_history = []

    def optimize_processing(self, performance_metrics: Dict) -> Dict:
        """ì²˜ë¦¬ ìµœì í™”"""
        
        # 1. ë³‘ëª© ì§€ì  ì‹ë³„
        bottleneck = self._identify_bottleneck(performance_metrics)
        
        # 2. ê°€ì¤‘ì¹˜ ì¡°ì •
        optimized_params = self._adjust_weights(bottleneck)
        
        # 3. ìµœì í™” íš¨ê³¼
        optimization_effect = self._calculate_optimization_effect(optimized_params)
        
        # 4. ê²€ì¦
        improvement = self._validate_improvement(performance_metrics, optimized_params)
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "bottleneck": bottleneck,
            "optimized_params": optimized_params,
            "optimization_effect": optimization_effect,
            "improvement_percentage": improvement,
            "status": "applied"
        }
        
        self.optimization_history.append(result)
        
        return result

    def _identify_bottleneck(self, metrics: Dict) -> str:
        """ë³‘ëª© ì§€ì  ì‹ë³„"""
        # ê°€ì¥ ë‚®ì€ ì ìˆ˜ ì°¾ê¸°
        lobe_scores = {
            "prefrontal": metrics.get("prefrontal_confidence", 0.85),
            "temporal": metrics.get("temporal_score", 0.80),
            "parietal": metrics.get("parietal_integration", 0.85),
            "occipital": metrics.get("occipital_analysis", 0.82)
        }
        
        bottleneck = min(lobe_scores, key=lobe_scores.get)
        return bottleneck

    def _adjust_weights(self, bottleneck: str) -> Dict:
        """ê°€ì¤‘ì¹˜ ì¡°ì •"""
        adjusted = self.optimization_params.copy()
        
        # ë³‘ëª© ì§€ì ì˜ ê°€ì¤‘ì¹˜ ì¦ê°€
        adjustment = 0.05
        
        for key in adjusted:
            if bottleneck in key:
                adjusted[key] += adjustment
            else:
                adjusted[key] -= adjustment / 3
        
        # ì •ê·œí™”
        total = sum(adjusted.values())
        for key in adjusted:
            adjusted[key] /= total
        
        self.optimization_params = adjusted
        
        return adjusted

    def _calculate_optimization_effect(self, params: Dict) -> float:
        """ìµœì í™” íš¨ê³¼"""
        # ê°€ì¤‘ì¹˜ í¸ì°¨ê°€ ì‘ì„ìˆ˜ë¡ ê· í˜•ì¡í˜
        mean = sum(params.values()) / len(params)
        variance = sum((v - mean) ** 2 for v in params.values()) / len(params)
        
        # 0-1 ë²”ìœ„ë¡œ ì •ê·œí™”
        effect = max(0.0, 1.0 - variance * 10)
        return round(effect, 3)

    def _validate_improvement(self, metrics: Dict, params: Dict) -> float:
        """ê°œì„  ê²€ì¦"""
        # ì˜ˆìƒ ê°œì„ ë¥ : ë³‘ëª© ì§€ì  ê°œì„  + ì „ì²´ ê· í˜•
        expected_improvement = 0.05 + (1.0 - max(metrics.values())) * 0.1
        
        return round(min(100.0, expected_improvement * 100), 2)


class NeuroNetL4:
    """L4 ì‹ ê²½ë§ - í†µí•© ì‹œìŠ¤í…œ"""
    
    def __init__(self):
        self.neural_router = NeuralRouter()
        self.neuroplasticity = Neuroplasticity()
        self.neural_optimizer = NeuralOptimizer()
        self.processing_log = []

    def process_with_neural_network(self, text: str, emotion: str, priority: str,
                                    l3_output: Dict) -> Dict:
        """ì‹ ê²½ë§ì„ í†µí•œ ì²˜ë¦¬"""
        
        logger.info(f"ğŸ§  L4 ì‹ ê²½ë§ ì²˜ë¦¬: {text[:30]}...")
        
        # 1ë‹¨ê³„: ì‹ ê²½ ì‹ í˜¸ ë¼ìš°íŒ…
        routing_result = self._route_neural_signals(emotion, priority)
        
        # 2ë‹¨ê³„: ì‹ ê²½ê°€ì†Œì„± ì ì‘
        adaptation_result = self._apply_neuroplasticity(text, l3_output)
        
        # 3ë‹¨ê³„: ì‹ ê²½ ìµœì í™”
        optimization_result = self._optimize_neural_system(l3_output)
        
        # 4ë‹¨ê³„: ìµœì¢… ê²°ì •
        final_decision = self._make_neural_decision(
            routing_result, adaptation_result, optimization_result, l3_output
        )
        
        result = {
            "timestamp": datetime.now().isoformat(),
            "input": text[:50],
            "routing": routing_result,
            "adaptation": adaptation_result,
            "optimization": optimization_result,
            "final_decision": final_decision,
            "system_confidence": self._calculate_system_confidence(
                routing_result, adaptation_result, optimization_result
            ),
            "neural_efficiency": self._calculate_neural_efficiency()
        }
        
        self.processing_log.append(result)
        
        return result

    def _route_neural_signals(self, emotion: str, priority: str) -> Dict:
        """ì‹ ê²½ ì‹ í˜¸ ë¼ìš°íŒ…"""
        # ì‹ í˜¸ ìƒì„±
        signal1 = NeuralSignal(
            signal_type=NeuralSignalType.EMOTIONAL,
            source="L2",
            destination="L3",
            data={"emotion": emotion, "priority": priority},
            strength=0.9
        )
        
        signal2 = NeuralSignal(
            signal_type=NeuralSignalType.COGNITIVE,
            source="L3",
            destination="Motor",
            data={"action": "execute"},
            strength=0.85
        )
        
        # ë¼ìš°íŒ…
        route1 = self.neural_router.route_signal(signal1)
        route2 = self.neural_router.route_signal(signal2)
        
        return {
            "routes_processed": 2,
            "routing_efficiency": self.neural_router.get_routing_efficiency(),
            "avg_latency_ms": (route1["latency_ms"] + route2["latency_ms"]) / 2,
            "success_rate": 1.0 if route1["success"] and route2["success"] else 0.5
        }

    def _apply_neuroplasticity(self, text: str, l3_output: Dict) -> Dict:
        """ì‹ ê²½ê°€ì†Œì„± ì ìš©"""
        # ì˜ˆìƒ ì¶œë ¥
        expected = l3_output.get("final_action", "ì²˜ë¦¬")
        
        # ì‹¤ì œ ì¶œë ¥ (ì‹œë®¬ë ˆì´ì…˜)
        actual = expected  # ì •í™•í•˜ë‹¤ê³  ê°€ì •
        
        adaptation = self.neuroplasticity.adapt_to_input(text, actual, expected)
        
        return {
            "learning_applied": True,
            "adaptation_score": adaptation["adaptation_score"],
            "average_adaptation": self.neuroplasticity.get_average_adaptation(),
            "weights_updated": adaptation["weights_updated"],
            "learning_signal_strength": adaptation["learning_signal"]
        }

    def _optimize_neural_system(self, l3_output: Dict) -> Dict:
        """ì‹ ê²½ ì‹œìŠ¤í…œ ìµœì í™”"""
        metrics = {
            "prefrontal_confidence": l3_output.get("prefrontal", {}).get("confidence", 0.85),
            "temporal_score": l3_output.get("temporal", {}).get("context_score", 0.80),
            "parietal_integration": l3_output.get("parietal", {}).get("integration_confidence", 0.85),
            "occipital_analysis": l3_output.get("occipital", {}).get("analysis_depth", 0.82)
        }
        
        optimization = self.neural_optimizer.optimize_processing(metrics)
        
        return optimization

    def _make_neural_decision(self, routing: Dict, adaptation: Dict, 
                            optimization: Dict, l3_output: Dict) -> Dict:
        """ì‹ ê²½ ê¸°ë°˜ ìµœì¢… ê²°ì •"""
        return {
            "primary_action": l3_output.get("final_action", "ì²˜ë¦¬"),
            "priority": l3_output.get("final_priority", "medium"),
            "neural_routing_confidence": routing["routing_efficiency"],
            "learning_confidence": adaptation["adaptation_score"],
            "optimization_applied": optimization["improvement_percentage"],
            "recommended_parameters": optimization["optimized_params"]
        }

    def _calculate_system_confidence(self, routing: Dict, adaptation: Dict, 
                                    optimization: Dict) -> float:
        """ì‹œìŠ¤í…œ ì‹ ë¢°ë„"""
        avg = (
            routing["routing_efficiency"] +
            adaptation["adaptation_score"] +
            (100 - optimization["improvement_percentage"]) / 100
        ) / 3
        
        return round(avg, 3)

    def _calculate_neural_efficiency(self) -> float:
        """ì‹ ê²½ íš¨ìœ¨ì„±"""
        if not self.processing_log:
            return 0.0
        
        confidences = [p["system_confidence"] for p in self.processing_log]
        return round(sum(confidences) / len(confidences), 3)


def main():
    """í…ŒìŠ¤íŠ¸"""
    logger.info("=" * 70)
    logger.info("ğŸš€ L4 ì‹ ê²½ë§ (NeuroNet) ì‹œìŠ¤í…œ í…ŒìŠ¤íŠ¸")
    logger.info("=" * 70)
    
    l4 = NeuroNetL4()
    
    # L3 ì¶œë ¥ ì‹œë®¬ë ˆì´ì…˜
    test_cases = [
        {
            "text": "ì‹ ê²½ê³„ ëª¨ë¸ ìµœì í™”ê°€ í•„ìš”í•´ìš”.",
            "emotion": "neutral",
            "priority": "critical",
            "l3_output": {
                "final_action": "ê¸´ê¸‰ ì²˜ë¦¬",
                "final_priority": "critical",
                "prefrontal": {"confidence": 0.91},
                "temporal": {"context_score": 0.88},
                "parietal": {"integration_confidence": 0.88},
                "occipital": {"analysis_depth": 0.85}
            }
        },
        {
            "text": "ë…¼ë¬¸ ê²€ìˆ˜ í”¼ë“œë°±ì„ ë°›ì•˜ì–´ìš”.",
            "emotion": "anxiety",
            "priority": "high",
            "l3_output": {
                "final_action": "ë°ì´í„° ì •ë¦¬",
                "final_priority": "high",
                "prefrontal": {"confidence": 0.89},
                "temporal": {"context_score": 0.85},
                "parietal": {"integration_confidence": 0.87},
                "occipital": {"analysis_depth": 0.84}
            }
        }
    ]
    
    results = []
    
    for test in test_cases:
        logger.info(f"\nğŸ“ ì²˜ë¦¬: {test['text'][:40]}...")
        
        result = l4.process_with_neural_network(
            test["text"], test["emotion"], test["priority"], test["l3_output"]
        )
        results.append(result)
        
        logger.info(f"  âœ… í–‰ë™: {result['final_decision']['primary_action']}")
        logger.info(f"  ğŸ¯ ìš°ì„ ìˆœìœ„: {result['final_decision']['priority']}")
        logger.info(f"  ğŸ“Š ì‹ ê²½ ì‹ ë¢°ë„: {result['system_confidence']:.3f}")
        logger.info(f"  ğŸ§¬ ì‹ ê²½ íš¨ìœ¨: {result['neural_efficiency']:.3f}")
    
    avg_confidence = sum(r["system_confidence"] for r in results) / len(results)
    
    logger.info("\n" + "=" * 70)
    logger.info(f"âœ… L4 ì‹ ê²½ë§ í…ŒìŠ¤íŠ¸ ì™„ë£Œ: {len(results)}ê°œ ì¼€ì´ìŠ¤")
    logger.info(f"ğŸ“Š í‰ê·  ì‹ ê²½ ì‹ ë¢°ë„: {avg_confidence:.3f}")
    logger.info(f"ğŸ¯ ëª©í‘œ: 10/10 (í˜„ì¬: {avg_confidence*10:.1f}/10)")
    logger.info("=" * 70)
    
    # JSON ì €ì¥
    with open("/Users/soohyunglee/.openclaw/workspace/systems/neural/l4_neuronet_results.json", "w") as f:
        json.dump({
            "timestamp": datetime.now().isoformat(),
            "system": "L4 NeuroNet",
            "total_tests": len(results),
            "average_confidence": avg_confidence,
            "score_out_of_10": avg_confidence * 10,
            "results": results
        }, f, indent=2, ensure_ascii=False)
    
    return results


if __name__ == "__main__":
    main()
