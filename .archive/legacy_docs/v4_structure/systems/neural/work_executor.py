"""
ğŸ§  ì‘ì—… ì‹¤í–‰ì (Work Executor)
WorkTrackerì™€ NeuralExecutorë¥¼ í†µí•©

ì—­í• : start_work â†’ execute â†’ end_workì˜ ì™„ì „í•œ ì‘ì—… ì‚¬ì´í´ ê´€ë¦¬
íŠ¹ì§•: ì‹ ê²½ê³„ ê¸°ë°˜ ì‘ì—… ì¶”ì , ìë™ ì ìˆ˜ ì—…ë°ì´íŠ¸, íš¨ìœ¨ ë©”íŠ¸ë¦­
"""

import json
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, Any, Callable, Optional, List
from enum import Enum


class WorkPhase(Enum):
    """ì‘ì—… ë‹¨ê³„"""
    STARTED = "started"
    IN_PROGRESS = "in_progress"
    COMPLETED = "completed"
    FAILED = "failed"


class WorkExecutor:
    """ì‘ì—… ì‹¤í–‰ ê´€ë¦¬ì"""
    
    def __init__(self):
        self.work_log_path = Path(__file__).parent / "work_execution_log.json"
        self.work_log = self._load_work_log()
    
    def _load_work_log(self) -> Dict:
        """ì‘ì—… ë¡œê·¸ ë¡œë“œ"""
        try:
            with open(self.work_log_path, "r", encoding="utf-8") as f:
                return json.load(f)
        except FileNotFoundError:
            return {"works": []}
    
    def start_work(
        self,
        work_id: str,
        work_name: str,
        task_type: str,
        neural_level: str,
        estimated_tokens: int = 0,
        priority: str = "normal"
    ) -> Dict:
        """
        ì‘ì—… ì‹œì‘
        
        Args:
            work_id: ì‘ì—… ID (ê³ ìœ )
            work_name: ì‘ì—… ì´ë¦„
            task_type: ì‘ì—… íƒ€ì… (coding, analysis, design, etc)
            neural_level: L1-L4
            estimated_tokens: ì˜ˆìƒ í† í°
            priority: ìš°ì„ ìˆœìœ„ (low, normal, high, critical)
        
        Returns:
            ì‘ì—… ì •ë³´
        """
        
        work = {
            "work_id": work_id,
            "work_name": work_name,
            "task_type": task_type,
            "neural_level": neural_level,
            "priority": priority,
            "phase": WorkPhase.STARTED.value,
            "start_time": datetime.now().isoformat(),
            "steps": [],
            "estimated_tokens": estimated_tokens,
            "actual_tokens": 0,
            "status": "ready"
        }
        
        self.work_log["works"].append(work)
        self._save_work_log()
        
        return work
    
    def log_step(
        self,
        work_id: str,
        step_name: str,
        step_type: str,
        model: str,
        tokens_used: int,
        duration_ms: int,
        quality_score: int,
        details: Optional[Dict] = None
    ) -> Dict:
        """
        ì‘ì—… ë‹¨ê³„ ê¸°ë¡
        
        Args:
            work_id: ì‘ì—… ID
            step_name: ë‹¨ê³„ ì´ë¦„
            step_type: ë‹¨ê³„ íƒ€ì… (analysis, coding, review, etc)
            model: ì‚¬ìš© ëª¨ë¸
            tokens_used: ì‚¬ìš©í•œ í† í°
            duration_ms: ì†Œìš” ì‹œê°„ (ms)
            quality_score: í’ˆì§ˆ ì ìˆ˜ (0-100)
            details: ìƒì„¸ ì •ë³´
        
        Returns:
            ê¸°ë¡ëœ ë‹¨ê³„ ì •ë³´
        """
        
        # ì‘ì—… ì°¾ê¸°
        work = self._find_work(work_id)
        if not work:
            return {"error": f"ì‘ì—… {work_id} ì—†ìŒ"}
        
        # ë‹¨ê³„ ìƒì„±
        step = {
            "step_id": f"{work_id}_step_{len(work['steps']) + 1}",
            "step_name": step_name,
            "step_type": step_type,
            "model": model,
            "timestamp": datetime.now().isoformat(),
            "tokens_used": tokens_used,
            "duration_ms": duration_ms,
            "quality_score": quality_score,
            "efficiency": self._calculate_efficiency(quality_score, tokens_used, duration_ms),
            "details": details or {}
        }
        
        # ì‘ì—…ì— ì¶”ê°€
        work["steps"].append(step)
        work["actual_tokens"] += tokens_used
        work["phase"] = WorkPhase.IN_PROGRESS.value
        
        self._save_work_log()
        
        return step
    
    def end_work(
        self,
        work_id: str,
        final_status: str,
        final_quality: int,
        summary: Optional[Dict] = None
    ) -> Dict:
        """
        ì‘ì—… ì¢…ë£Œ
        
        Args:
            work_id: ì‘ì—… ID
            final_status: success, partial, failure
            final_quality: ìµœì¢… í’ˆì§ˆ ì ìˆ˜ (0-100)
            summary: ì‘ì—… ìš”ì•½
        
        Returns:
            ì‘ì—… ê²°ê³¼
        """
        
        work = self._find_work(work_id)
        if not work:
            return {"error": f"ì‘ì—… {work_id} ì—†ìŒ"}
        
        end_time = datetime.now()
        start_time = datetime.fromisoformat(work["start_time"])
        duration = (end_time - start_time).total_seconds()
        
        # ì‘ì—… ê²°ê³¼ ê³„ì‚°
        work["phase"] = WorkPhase.COMPLETED.value if final_status == "success" else WorkPhase.FAILED.value
        work["end_time"] = end_time.isoformat()
        work["duration_seconds"] = duration
        work["final_status"] = final_status
        work["final_quality"] = final_quality
        work["summary"] = summary or {}
        
        # íš¨ìœ¨ ë©”íŠ¸ë¦­
        avg_step_quality = sum(s.get("quality_score", 0) for s in work["steps"]) / len(work["steps"]) if work["steps"] else 0
        avg_step_efficiency = sum(s.get("efficiency", 0) for s in work["steps"]) / len(work["steps"]) if work["steps"] else 0
        
        work["metrics"] = {
            "total_steps": len(work["steps"]),
            "avg_quality": round(avg_step_quality, 1),
            "avg_efficiency": round(avg_step_efficiency, 1),
            "token_efficiency": round(work["actual_tokens"] / max(1, duration / 60), 1),  # tokens/min
            "time_efficiency": round(duration / len(work["steps"]), 1) if work["steps"] else 0,  # sec/step
            "token_vs_estimate": round(work["actual_tokens"] / max(1, work["estimated_tokens"]), 2) if work["estimated_tokens"] else 0
        }
        
        self._save_work_log()
        
        return work
    
    def get_work_summary(self, work_id: str) -> Dict:
        """ì‘ì—… ìš”ì•½ ì¡°íšŒ"""
        
        work = self._find_work(work_id)
        if not work:
            return {"error": f"ì‘ì—… {work_id} ì—†ìŒ"}
        
        return {
            "work_id": work_id,
            "work_name": work["work_name"],
            "status": work.get("phase"),
            "task_type": work["task_type"],
            "neural_level": work["neural_level"],
            "priority": work["priority"],
            "start_time": work["start_time"],
            "end_time": work.get("end_time"),
            "duration_seconds": work.get("duration_seconds", 0),
            "steps": len(work["steps"]),
            "tokens_used": work["actual_tokens"],
            "final_quality": work.get("final_quality", 0),
            "metrics": work.get("metrics", {}),
            "timestamp": datetime.now().isoformat()
        }
    
    def get_daily_work_report(self) -> Dict:
        """ì¼ì¼ ì‘ì—… ë¦¬í¬íŠ¸"""
        
        today = datetime.now().date().isoformat()
        today_works = [
            w for w in self.work_log["works"]
            if w["start_time"].startswith(today)
        ]
        
        if not today_works:
            return {"date": today, "total_works": 0}
        
        total_works = len(today_works)
        completed = sum(1 for w in today_works if w.get("phase") == WorkPhase.COMPLETED.value)
        failed = sum(1 for w in today_works if w.get("phase") == WorkPhase.FAILED.value)
        
        total_duration = sum(w.get("duration_seconds", 0) for w in today_works)
        total_tokens = sum(w["actual_tokens"] for w in today_works)
        avg_quality = sum(w.get("final_quality", 0) for w in today_works) / total_works if total_works > 0 else 0
        
        # ì‹ ê²½ê³„ë³„ í†µê³„
        neural_stats = {}
        for level in ["L1", "L2", "L3", "L4"]:
            level_works = [w for w in today_works if w["neural_level"] == level]
            if level_works:
                neural_stats[level] = {
                    "count": len(level_works),
                    "avg_quality": round(sum(w.get("final_quality", 0) for w in level_works) / len(level_works), 1),
                    "total_tokens": sum(w["actual_tokens"] for w in level_works)
                }
        
        return {
            "date": today,
            "total_works": total_works,
            "completed": completed,
            "failed": failed,
            "completion_rate": round(completed / total_works * 100, 1) if total_works > 0 else 0,
            "total_duration_hours": round(total_duration / 3600, 2),
            "total_tokens": total_tokens,
            "avg_quality": round(avg_quality, 1),
            "neural_stats": neural_stats,
            "timestamp": datetime.now().isoformat()
        }
    
    def _find_work(self, work_id: str) -> Optional[Dict]:
        """ì‘ì—… ì°¾ê¸°"""
        for work in self.work_log["works"]:
            if work["work_id"] == work_id:
                return work
        return None
    
    def _calculate_efficiency(
        self,
        quality_score: int,
        tokens_used: int,
        duration_ms: int
    ) -> float:
        """íš¨ìœ¨ ì ìˆ˜ ê³„ì‚° (0-100)"""
        
        # í’ˆì§ˆ (40%)
        quality_score_norm = quality_score / 100 * 0.4
        
        # í† í° íš¨ìœ¨ (30%) - ì ì„ìˆ˜ë¡ ì¢‹ìŒ
        token_score = min(1, 1000 / max(1, tokens_used)) * 0.3
        
        # ì†ë„ (30%) - ë¹ ë¥¼ìˆ˜ë¡ ì¢‹ìŒ
        speed_score = min(1, 1000 / max(1, duration_ms)) * 0.3
        
        efficiency = (quality_score_norm + token_score + speed_score) * 100
        
        return round(efficiency, 1)
    
    def _save_work_log(self):
        """ì‘ì—… ë¡œê·¸ ì €ì¥"""
        with open(self.work_log_path, "w", encoding="utf-8") as f:
            json.dump(self.work_log, f, indent=2, ensure_ascii=False)


# ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    executor = WorkExecutor()
    
    print("ğŸ§  ì‘ì—… ì‹¤í–‰ì í…ŒìŠ¤íŠ¸\n")
    
    # ì‘ì—… 1: ë¶„ì„ ì‘ì—…
    work1 = executor.start_work(
        work_id="work_001",
        work_name="ì‹ ê²½ê³„ ì„±ëŠ¥ ë¶„ì„",
        task_type="analysis",
        neural_level="L3",
        estimated_tokens=5000,
        priority="high"
    )
    print(f"âœ… ì‘ì—… ì‹œì‘: {work1['work_name']}\n")
    
    # ë‹¨ê³„ 1: ë°ì´í„° ìˆ˜ì§‘
    step1 = executor.log_step(
        work_id="work_001",
        step_name="ë°ì´í„° ìˆ˜ì§‘",
        step_type="analysis",
        model="Gemini",
        tokens_used=1000,
        duration_ms=2000,
        quality_score=95
    )
    print(f"ğŸ“ ë‹¨ê³„: {step1['step_name']} ({step1['quality_score']}/100)\n")
    
    # ë‹¨ê³„ 2: ë¶„ì„
    step2 = executor.log_step(
        work_id="work_001",
        step_name="ì„±ëŠ¥ ë¶„ì„",
        step_type="analysis",
        model="Claude",
        tokens_used=3000,
        duration_ms=4000,
        quality_score=92
    )
    print(f"ğŸ“ ë‹¨ê³„: {step2['step_name']} ({step2['quality_score']}/100)\n")
    
    # ì‘ì—… ì¢…ë£Œ
    result = executor.end_work(
        work_id="work_001",
        final_status="success",
        final_quality=94,
        summary={"analysis": "ì™„ë£Œ"}
    )
    print(f"âœ… ì‘ì—… ì™„ë£Œ")
    print(f"   ìƒíƒœ: {result['final_status']}")
    print(f"   í’ˆì§ˆ: {result['final_quality']}/100")
    print(f"   ì†Œìš”ì‹œê°„: {result['duration_seconds']:.1f}ì´ˆ")
    print(f"   í† í°: {result['actual_tokens']}\n")
    
    # ì¼ì¼ ë¦¬í¬íŠ¸
    report = executor.get_daily_work_report()
    print(f"ğŸ“Š ì¼ì¼ ë¦¬í¬íŠ¸")
    print(f"   ì´ ì‘ì—…: {report['total_works']}")
    print(f"   ì™„ë£Œ: {report['completed']}")
    print(f"   ì„±ê³µë¥ : {report['completion_rate']}%")
    print(f"   í‰ê·  í’ˆì§ˆ: {report['avg_quality']}/100")
