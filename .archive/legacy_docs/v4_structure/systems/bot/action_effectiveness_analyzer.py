#!/usr/bin/env python3
"""
action_effectiveness_analyzer.py - í–‰ë™(ì•¡ì…˜) íš¨ìœ¨ì„± ë¶„ì„

Week 2 Step 2: ê° ì•¡ì…˜ë³„ ì„±ê³µë¥  ë¶„ì„ ë° ìµœì í™” ì¶”ì²œ

ì—­í• :
  â”œâ”€ ê° ì•¡ì…˜(Action)ë³„ ì„±ê³µë¥  ê³„ì‚°
  â”œâ”€ ìƒíƒœë³„ ìµœì  ì•¡ì…˜ íŒŒì•…
  â”œâ”€ ë¹„íš¨ìœ¨ì  ì•¡ì…˜ ê°ì§€ (< 30% ì„±ê³µë¥ )
  â”œâ”€ ì•¡ì…˜ ì¡°í•© ìµœì í™”
  â””â”€ ì„±ëŠ¥ ê°œì„  ì¶”ì²œ

5ê°€ì§€ ì•¡ì…˜:
  1. RESTART_IMMEDIATELY: ì¦‰ì‹œ ì¬ì‹œì‘ (ë¹ ë¥´ì§€ë§Œ ìœ„í—˜)
  2. CHECK_DEPENDENCIES_FIRST: ì˜ì¡´ì„± í™•ì¸ í›„ ì¬ì‹œì‘ (ëŠë¦¬ì§€ë§Œ ì•ˆì „)
  3. WAIT_AND_RETRY: ëŒ€ê¸° í›„ ì¬ì‹œë„ (ê°€ì¥ ëŠë¦¼, ìµœí›„ ìˆ˜ë‹¨)
  4. ESCALATE_TO_MANUAL: ìˆ˜ë™ ê°œì… (ì‚¬ëŒì´ í•  ë•Œê¹Œì§€ ëŒ€ê¸°)
  5. RESTART_WITH_CLEAN_ENV: í™˜ê²½ ì´ˆê¸°í™” í›„ ì¬ì‹œì‘ (ê°€ì¥ ì•ˆì „)
"""

import json
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Tuple, Optional
import statistics


class ActionEffectivenessAnalyzer:
    """ì•¡ì…˜ íš¨ìœ¨ì„± ë¶„ì„"""
    
    def __init__(self, q_table_path: str = "systems/bot/watchdog_q_table.json"):
        self.q_table_path = Path(q_table_path)
        self.q_values: Dict[str, float] = {}
        self.state_action_map: Dict[str, List[str]] = {}
        self.load_q_table()
        self._build_state_action_map()
    
    def load_q_table(self) -> None:
        """Q-Table ë¡œë“œ"""
        if self.q_table_path.exists():
            with open(self.q_table_path, 'r') as f:
                data = json.load(f)
                self.q_values = data.get('q_values', {})
            print(f"âœ… Q-Table ë¡œë“œ: {len(self.q_values)}ê°œ í•­ëª©")
        else:
            print(f"âŒ Q-Table ì—†ìŒ")
            self._create_sample_data()
    
    def _create_sample_data(self) -> None:
        """ìƒ˜í”Œ ë°ì´í„° ìƒì„±"""
        self.q_values = {
            "running_restart_immediately": 8.5,
            "running_check_dependencies": 7.2,
            "running_wait_and_retry": 6.8,
            "down_restart_immediately": 15.0,
            "down_check_dependencies": 13.5,
            "down_wait_and_retry": 12.5,
            "down_escalate_manual": 5.0,
            "down_restart_clean": 14.0,
            "sleeping_check_dependencies": 9.5,
            "sleeping_wait_and_retry": 8.0,
            "error_escalate_manual": 6.0,
            "error_restart_clean": 11.0,
            "zombie_restart_clean": 13.5,
            "zombie_escalate_manual": 4.5,
        }
    
    def _build_state_action_map(self) -> None:
        """ìƒíƒœ-ì•¡ì…˜ ë§µ êµ¬ì¶•"""
        for state_action, q_value in self.q_values.items():
            if '_' in state_action:
                parts = state_action.rsplit('_', 1)
                if len(parts) == 2:
                    state = parts[0]
                    action = parts[1]
                    
                    if state not in self.state_action_map:
                        self.state_action_map[state] = []
                    
                    self.state_action_map[state].append(action)
    
    def analyze_action_effectiveness(self) -> Dict:
        """ê° ì•¡ì…˜ì˜ íš¨ìœ¨ì„± ë¶„ì„"""
        
        print("\n" + "="*80)
        print("ğŸ“Š ì•¡ì…˜ íš¨ìœ¨ì„± ë¶„ì„")
        print("="*80)
        
        action_stats = self._calculate_action_statistics()
        
        print(f"""
ğŸ¯ ê° ì•¡ì…˜ë³„ Q ê°’ í†µê³„:
""")
        
        # ì•¡ì…˜ë³„ í†µê³„ ì¶œë ¥
        sorted_actions = sorted(
            action_stats.items(),
            key=lambda x: x[1]['avg_q'],
            reverse=True
        )
        
        for action, stats in sorted_actions:
            print(f"""
   {action}:
      â€¢ í‰ê·  Q ê°’: {stats['avg_q']:.2f}
      â€¢ ìµœëŒ“ê°’: {stats['max_q']:.2f}
      â€¢ ìµœì†Ÿê°’: {stats['min_q']:.2f}
      â€¢ ì‚¬ìš© íšŸìˆ˜: {stats['count']}
      â€¢ í‰ê·  ì„±ê³µë¥  ì¶”ì •: {stats['estimated_success_rate']:.1%}
""")
        
        return action_stats
    
    def _calculate_action_statistics(self) -> Dict[str, Dict]:
        """ì•¡ì…˜ë³„ í†µê³„ ê³„ì‚°"""
        
        actions = {}
        
        for state_action, q_value in self.q_values.items():
            if '_' in state_action:
                parts = state_action.rsplit('_', 1)
                if len(parts) == 2:
                    action = parts[1]
                    
                    if action not in actions:
                        actions[action] = {
                            'q_values': [],
                            'count': 0,
                            'states': set()
                        }
                    
                    actions[action]['q_values'].append(q_value)
                    actions[action]['count'] += 1
                    actions[action]['states'].add(parts[0])
        
        # í†µê³„ ê³„ì‚°
        result = {}
        for action, data in actions.items():
            q_vals = data['q_values']
            avg_q = statistics.mean(q_vals) if q_vals else 0
            
            # Q ê°’ì„ ì„±ê³µë¥ ë¡œ ê·¼ì‚¬ (Qê°’ì´ ë†’ì„ìˆ˜ë¡ ì„±ê³µë¥  ë†’ìŒ)
            # ì •ê·œí™”: (Q - min) / (max - min) * 100
            if q_vals:
                min_q = min(q_vals)
                max_q = max(q_vals)
                estimated_success_rate = (avg_q - min_q) / (max_q - min_q) if max_q != min_q else 0.5
            else:
                estimated_success_rate = 0.5
            
            result[action] = {
                'avg_q': avg_q,
                'max_q': max(q_vals) if q_vals else 0,
                'min_q': min(q_vals) if q_vals else 0,
                'count': data['count'],
                'states': len(data['states']),
                'estimated_success_rate': max(0, min(1, estimated_success_rate))
            }
        
        return result
    
    def identify_ineffective_actions(self, threshold: float = 0.3) -> Dict:
        """ë¹„íš¨ìœ¨ì  ì•¡ì…˜ ê°ì§€"""
        
        print("\n" + "="*80)
        print("ğŸš¨ ë¹„íš¨ìœ¨ì  ì•¡ì…˜ ê°ì§€")
        print("="*80)
        
        action_stats = self._calculate_action_statistics()
        ineffective = []
        
        for action, stats in action_stats.items():
            success_rate = stats['estimated_success_rate']
            
            if success_rate < threshold:
                ineffective.append({
                    'action': action,
                    'success_rate': success_rate,
                    'avg_q': stats['avg_q'],
                    'recommendation': self._get_recommendation(action, stats)
                })
                
                print(f"""
âš ï¸ {action}:
   â€¢ ì„±ê³µë¥ : {success_rate:.1%} (ê¸°ì¤€: {threshold:.1%})
   â€¢ í‰ê·  Q ê°’: {stats['avg_q']:.2f}
   â€¢ ì‚¬ìš©ëœ ìƒíƒœ: {stats['states']}ê°œ
   â€¢ ì¶”ì²œ: {self._get_recommendation(action, stats)}
""")
        
        if not ineffective:
            print("âœ… ëª¨ë“  ì•¡ì…˜ì´ íš¨ìœ¨ì ì…ë‹ˆë‹¤ (ì„±ê³µë¥  > 30%)")
        
        return {
            'ineffective_actions': ineffective,
            'threshold': threshold
        }
    
    def _get_recommendation(self, action: str, stats: Dict) -> str:
        """ì•¡ì…˜ë³„ ê°œì„  ê¶Œì¥ì‚¬í•­"""
        
        recommendations = {
            'restart_immediately': "ë¹ ë¥´ì§€ë§Œ ìœ„í—˜í•¨. ì „ì œ ì¡°ê±´ ì¶”ê°€ ê²€ì‚¬ í•„ìš”",
            'check_dependencies': "ì•ˆì „í•˜ì§€ë§Œ ëŠë¦¼. ìºì‹±ìœ¼ë¡œ ì†ë„ ê°œì„  í•„ìš”",
            'wait_and_retry': "íš¨ìœ¨ ë‚®ìŒ. ê°ì†Œ ì¶”ì²œ ë˜ëŠ” ì œê±° ê²€í† ",
            'escalate_manual': "ìˆ˜ë™ ê°œì… í•„ìš”. ìë™í™” ê°€ëŠ¥ì„± ê²€í† ",
            'restart_clean': "ì•ˆì „í•¨. ê³„ì† ì‚¬ìš© ê¶Œì¥"
        }
        
        for key, rec in recommendations.items():
            if key in action:
                return rec
        
        return "ê°œì„  í•„ìš”"
    
    def optimize_by_state(self) -> Dict:
        """ìƒíƒœë³„ ìµœì  ì•¡ì…˜ ì¶”ì²œ"""
        
        print("\n" + "="*80)
        print("ğŸ¯ ìƒíƒœë³„ ìµœì  ì•¡ì…˜ ì¶”ì²œ")
        print("="*80)
        
        state_optimal_actions = {}
        
        for state, actions in self.state_action_map.items():
            best_q = -float('inf')
            best_action = None
            
            for action in actions:
                key = f"{state}_{action}"
                q_value = self.q_values.get(key, -float('inf'))
                
                if q_value > best_q:
                    best_q = q_value
                    best_action = action
            
            state_optimal_actions[state] = {
                'best_action': best_action,
                'q_value': best_q
            }
            
            print(f"""
ìƒíƒœ: {state}
   â€¢ ìµœì  ì•¡ì…˜: {best_action}
   â€¢ Q ê°’: {best_q:.2f}
   â€¢ ëª¨ë“  ì•¡ì…˜: {', '.join(actions)}
""")
        
        return state_optimal_actions
    
    def generate_optimization_report(self) -> Dict:
        """ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±"""
        
        print("\n" + "="*80)
        print("ğŸ“‹ ìµœì í™” ë¦¬í¬íŠ¸ ìƒì„±")
        print("="*80)
        
        action_effectiveness = self.analyze_action_effectiveness()
        ineffective = self.identify_ineffective_actions()
        optimal_by_state = self.optimize_by_state()
        
        # ì „ì²´ ìš”ì•½
        total_actions = len(action_effectiveness)
        ineffective_count = len(ineffective['ineffective_actions'])
        effective_count = total_actions - ineffective_count
        
        report = {
            'timestamp': datetime.now().isoformat(),
            'action_effectiveness': action_effectiveness,
            'ineffective_actions': ineffective['ineffective_actions'],
            'optimal_actions_by_state': optimal_by_state,
            'summary': {
                'total_actions': total_actions,
                'effective_actions': effective_count,
                'ineffective_actions': ineffective_count,
                'overall_effectiveness': (effective_count / total_actions * 100) if total_actions > 0 else 0
            },
            'recommendations': self._generate_recommendations(
                action_effectiveness,
                ineffective['ineffective_actions'],
                optimal_by_state
            )
        }
        
        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = Path("logs/neural_efficiency/action_effectiveness_report.json")
        report_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(report_path, 'w') as f:
            json.dump(report, f, indent=2)
        
        print(f"\nâœ… ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        
        return report
    
    def _generate_recommendations(self, effectiveness: Dict, ineffective: List, optimal: Dict) -> Dict:
        """ìµœì í™” ê¶Œì¥ì‚¬í•­ ìƒì„±"""
        
        recommendations = {
            'immediate_actions': [],
            'medium_term_improvements': [],
            'long_term_optimizations': []
        }
        
        # ì¦‰ì‹œ ì¡°ì¹˜ í•„ìš” (ì„±ê³µë¥  < 20%)
        for item in ineffective:
            if item['success_rate'] < 0.2:
                recommendations['immediate_actions'].append(
                    f"âŒ {item['action']} ë¹„í™œì„±í™” (ì„±ê³µë¥  {item['success_rate']:.1%})"
                )
        
        # ë‹¨ê¸° ê°œì„  (ì„±ê³µë¥  20-40%)
        for action, stats in effectiveness.items():
            if 0.2 < stats['estimated_success_rate'] < 0.4:
                recommendations['medium_term_improvements'].append(
                    f"âš ï¸ {action} ê°œì„  (ì„±ê³µë¥  {stats['estimated_success_rate']:.1%})"
                )
        
        # ì¥ê¸° ìµœì í™”
        recommendations['long_term_optimizations'].append(
            "âœ… ìƒíƒœë³„ ìµœì  ì•¡ì…˜ ìš°ì„  ì‚¬ìš©"
        )
        recommendations['long_term_optimizations'].append(
            "âœ… Q-Learning ìˆ˜ë ´ í›„ ì •ì±… ë°°í¬"
        )
        recommendations['long_term_optimizations'].append(
            "âœ… ì•¡ì…˜ ì¡°í•© ë°©ì‹ ë„ì… (ì—¬ëŸ¬ ì•¡ì…˜ ìˆœì°¨ ì‹¤í–‰)"
        )
        
        return recommendations


def main():
    """ë©”ì¸ ì‹¤í–‰"""
    
    print("""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  ğŸ“Š ì•¡ì…˜ íš¨ìœ¨ì„± ë¶„ì„                                                        â•‘
â•‘     Week 2 Step 2: ë³µêµ¬ ì „ëµ ìµœì í™”                                           â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")
    
    analyzer = ActionEffectivenessAnalyzer()
    report = analyzer.generate_optimization_report()
    
    # ìµœì¢… ìš”ì•½
    summary = report['summary']
    recommendations = report['recommendations']
    
    print(f"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ¨ ë¶„ì„ ì™„ë£Œ
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

ğŸ“Š ìš”ì•½:
   â€¢ ì´ ì•¡ì…˜: {summary['total_actions']}ê°œ
   â€¢ íš¨ìœ¨ì  ì•¡ì…˜: {summary['effective_actions']}ê°œ
   â€¢ ë¹„íš¨ìœ¨ì  ì•¡ì…˜: {summary['ineffective_actions']}ê°œ
   â€¢ ì „ì²´ íš¨ìœ¨: {summary['overall_effectiveness']:.1f}%

ğŸ“‹ ì¦‰ì‹œ ì¡°ì¹˜:
""")
    
    if recommendations['immediate_actions']:
        for rec in recommendations['immediate_actions']:
            print(f"   {rec}")
    else:
        print("   âœ… ëª¨ë‘ ì–‘í˜¸í•©ë‹ˆë‹¤")
    
    print(f"""
ğŸ“‹ ë‹¨ê¸° ê°œì„ :
""")
    
    if recommendations['medium_term_improvements']:
        for rec in recommendations['medium_term_improvements']:
            print(f"   {rec}")
    else:
        print("   âœ… ì—†ìŒ")
    
    print(f"""
ğŸ“‹ ì¥ê¸° ìµœì í™”:
""")
    
    for rec in recommendations['long_term_optimizations']:
        print(f"   {rec}")
    
    print(f"""
ìƒì„¸ ë¦¬í¬íŠ¸: logs/neural_efficiency/action_effectiveness_report.json
""")


if __name__ == "__main__":
    main()
