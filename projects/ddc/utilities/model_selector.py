"""
AI ëª¨ë¸ í†µí•© ê°•í™” - ìë™ ëª¨ë¸ ì„ íƒ & í´ë°±

ì—­í• :
- ì‘ì—… ìœ í˜•ë³„ ìµœì  ëª¨ë¸ ì„ íƒ
- ëª¨ë¸ ì„±ëŠ¥ ì¶”ì 
- ìë™ í´ë°± ë©”ì»¤ë‹ˆì¦˜
- ë¹„ìš© ìµœì í™”
"""

from typing import Dict, List, Optional, Callable, Any
from enum import Enum
from dataclasses import dataclass
import time


class TaskType(Enum):
    """ì‘ì—… ìœ í˜•"""
    IMAGE_ANALYSIS = "image_analysis"      # ì´ë¯¸ì§€ ë¶„ì„ (Occipital)
    TEXT_ANALYSIS = "text_analysis"        # í…ìŠ¤íŠ¸ ë¶„ì„ (Temporal)
    QUANTITATIVE = "quantitative"          # ì •ëŸ‰ ë¶„ì„ (Parietal)
    DECISION_MAKING = "decision_making"    # ì˜ì‚¬ê²°ì • (Prefrontal)
    RAPID_RESPONSE = "rapid_response"      # ë¹ ë¥¸ ì‘ë‹µ (Brainstem)
    GENERAL = "general"                    # ì¼ë°˜ ëŒ€í™”


@dataclass
class ModelProfile:
    """ëª¨ë¸ í”„ë¡œí•„"""
    name: str
    task_types: List[TaskType]
    cost_per_call: float
    avg_latency_ms: float
    accuracy_score: float  # 0-1
    success_rate: float    # 0-1
    available: bool = True


class ModelSelector:
    """ëª¨ë¸ ì„ íƒê¸°"""
    
    def __init__(self):
        # ëª¨ë¸ í”„ë¡œí•„ ì •ì˜
        self.models = {
            'gemini_2_5_pro': ModelProfile(
                name='Gemini 2.5 Pro',
                task_types=[
                    TaskType.IMAGE_ANALYSIS,
                    TaskType.TEXT_ANALYSIS,
                    TaskType.DECISION_MAKING,
                    TaskType.GENERAL
                ],
                cost_per_call=0.01,
                avg_latency_ms=2300,
                accuracy_score=0.99,
                success_rate=0.98
            ),
            'claude_opus': ModelProfile(
                name='Claude Opus',
                task_types=[
                    TaskType.DECISION_MAKING,
                    TaskType.TEXT_ANALYSIS,
                    TaskType.GENERAL
                ],
                cost_per_call=0.015,
                avg_latency_ms=2100,
                accuracy_score=0.99,
                success_rate=0.97
            ),
            'groq_llama': ModelProfile(
                name='Groq Llama',
                task_types=[
                    TaskType.RAPID_RESPONSE,
                    TaskType.GENERAL
                ],
                cost_per_call=0.0,
                avg_latency_ms=800,
                accuracy_score=0.92,
                success_rate=0.95
            ),
            'deepseek': ModelProfile(
                name='DeepSeek',
                task_types=[
                    TaskType.QUANTITATIVE,
                    TaskType.TEXT_ANALYSIS
                ],
                cost_per_call=0.002,
                avg_latency_ms=1500,
                accuracy_score=0.95,
                success_rate=0.93
            ),
            'claude_sonnet': ModelProfile(
                name='Claude Sonnet',
                task_types=[
                    TaskType.TEXT_ANALYSIS,
                    TaskType.GENERAL
                ],
                cost_per_call=0.003,
                avg_latency_ms=1800,
                accuracy_score=0.97,
                success_rate=0.96
            ),
            'gemini_flash': ModelProfile(
                name='Gemini Flash',
                task_types=[
                    TaskType.RAPID_RESPONSE,
                    TaskType.GENERAL
                ],
                cost_per_call=0.0005,
                avg_latency_ms=900,
                accuracy_score=0.90,
                success_rate=0.94
            )
        }
        
        # ì‘ì—… ìœ í˜•ë³„ ìš°ì„ ìˆœìœ„
        self.task_preferences = {
            TaskType.IMAGE_ANALYSIS: ['gemini_2_5_pro', 'claude_opus'],
            TaskType.TEXT_ANALYSIS: ['claude_opus', 'gemini_2_5_pro', 'claude_sonnet'],
            TaskType.QUANTITATIVE: ['deepseek', 'gemini_2_5_pro'],
            TaskType.DECISION_MAKING: ['claude_opus', 'gemini_2_5_pro'],
            TaskType.RAPID_RESPONSE: ['groq_llama', 'gemini_flash'],
            TaskType.GENERAL: ['gemini_2_5_pro', 'claude_sonnet', 'groq_llama']
        }
    
    def select_model(
        self,
        task_type: TaskType,
        priority: str = 'balanced'  # 'cost', 'speed', 'accuracy', 'balanced'
    ) -> ModelProfile:
        """ëª¨ë¸ ì„ íƒ"""
        candidates = self.task_preferences.get(task_type, [])
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ í•„í„°ë§
        available = [
            self.models[m] for m in candidates
            if m in self.models and self.models[m].available
        ]
        
        if not available:
            # í´ë°±: ì²« ë²ˆì§¸ ì‚¬ìš© ê°€ëŠ¥ ëª¨ë¸
            for model in self.models.values():
                if model.available:
                    return model
        
        # ìš°ì„ ìˆœìœ„ì— ë”°ë¼ ì •ë ¬
        if priority == 'cost':
            available.sort(key=lambda x: x.cost_per_call)
        elif priority == 'speed':
            available.sort(key=lambda x: x.avg_latency_ms)
        elif priority == 'accuracy':
            available.sort(key=lambda x: x.accuracy_score, reverse=True)
        else:  # balanced
            # ë¹„ìš©-ì„±ëŠ¥ ë¹„ìœ¨ ê³„ì‚°
            available.sort(key=lambda x: x.accuracy_score / (x.cost_per_call + 0.001), reverse=True)
        
        return available[0]
    
    def get_alternatives(self, task_type: TaskType, count: int = 3) -> List[ModelProfile]:
        """ëŒ€ì²´ ëª¨ë¸ ëª©ë¡"""
        candidates = self.task_preferences.get(task_type, [])
        
        available = [
            self.models[m] for m in candidates
            if m in self.models and self.models[m].available
        ]
        
        available.sort(key=lambda x: x.accuracy_score, reverse=True)
        return available[:count]


class FallbackStrategy:
    """í´ë°± ì „ëµ"""
    
    def __init__(self, selector: ModelSelector):
        self.selector = selector
        self.fallback_chain = []
        self.attempt_count = {}
    
    def execute_with_fallback(
        self,
        task_type: TaskType,
        func: Callable,
        *args,
        **kwargs
    ) -> Optional[Any]:
        """í´ë°±ê³¼ í•¨ê»˜ ì‹¤í–‰"""
        models = [self.selector.select_model(task_type)] + self.selector.get_alternatives(task_type, 2)
        
        for i, model in enumerate(models):
            try:
                # ëª¨ë¸ ì‚¬ìš© ì‹œë„
                print(f"ğŸ¤– ì‹œë„ {i+1}: {model.name}")
                
                # ëª¨ë¸ ì§€ì •
                kwargs['model'] = model.name
                
                result = func(*args, **kwargs)
                print(f"âœ… {model.name}ìœ¼ë¡œ ì„±ê³µ!")
                return result
                
            except Exception as e:
                print(f"âš ï¸ {model.name} ì‹¤íŒ¨: {str(e)}")
                
                if i == len(models) - 1:
                    # ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨
                    print(f"âŒ ëª¨ë“  ëª¨ë¸ ì‹¤íŒ¨!")
                    return None
                
                continue


class ModelMonitor:
    """ëª¨ë¸ ëª¨ë‹ˆí„°ë§"""
    
    def __init__(self):
        self.call_history = {
            'success': {},
            'failure': {},
            'latency': {},
            'cost': {}
        }
    
    def record_call(
        self,
        model_name: str,
        task_type: str,
        duration_ms: float,
        cost: float,
        success: bool
    ):
        """í˜¸ì¶œ ê¸°ë¡"""
        key = f"{model_name}_{task_type}"
        
        if success:
            self.call_history['success'][key] = self.call_history['success'].get(key, 0) + 1
        else:
            self.call_history['failure'][key] = self.call_history['failure'].get(key, 0) + 1
        
        if key not in self.call_history['latency']:
            self.call_history['latency'][key] = []
        self.call_history['latency'][key].append(duration_ms)
        
        if key not in self.call_history['cost']:
            self.call_history['cost'][key] = 0
        self.call_history['cost'][key] += cost
    
    def get_model_stats(self, model_name: str) -> Dict[str, Any]:
        """ëª¨ë¸ í†µê³„"""
        keys = [k for k in self.call_history['success'].keys() if k.startswith(model_name)]
        
        total_success = sum(self.call_history['success'].get(k, 0) for k in keys)
        total_failure = sum(self.call_history['failure'].get(k, 0) for k in keys)
        total_calls = total_success + total_failure
        
        if total_calls == 0:
            return {}
        
        all_latencies = []
        for k in keys:
            all_latencies.extend(self.call_history['latency'].get(k, []))
        
        total_cost = sum(self.call_history['cost'].get(k, 0) for k in keys)
        
        return {
            'total_calls': total_calls,
            'success_rate': total_success / total_calls,
            'failure_rate': total_failure / total_calls,
            'avg_latency_ms': sum(all_latencies) / len(all_latencies) if all_latencies else 0,
            'total_cost': total_cost,
            'cost_per_call': total_cost / total_calls if total_calls > 0 else 0
        }
    
    def print_stats(self):
        """í†µê³„ ì¶œë ¥"""
        print("\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
        print("â•‘         ğŸ¤– ëª¨ë¸ë³„ ì„±ëŠ¥ í†µê³„                        â•‘")
        print("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n")
        
        models = set(k.split('_')[0] for k in self.call_history['success'].keys())
        
        for model in models:
            stats = self.get_model_stats(model)
            if stats:
                print(f"ğŸ“Š {model}")
                print(f"  í˜¸ì¶œ: {stats['total_calls']}")
                print(f"  ì„±ê³µë¥ : {stats['success_rate']*100:.1f}%")
                print(f"  í‰ê·  ì§€ì—°: {stats['avg_latency_ms']:.0f}ms")
                print(f"  ì´ ë¹„ìš©: ${stats['total_cost']:.4f}")
                print(f"  í˜¸ì¶œë‹¹ ë¹„ìš©: ${stats['cost_per_call']:.6f}")
                print()


if __name__ == "__main__":
    print("ğŸ¤– AI ëª¨ë¸ í†µí•© ê°•í™” í…ŒìŠ¤íŠ¸\n")
    
    # ëª¨ë¸ ì„ íƒê¸° ìƒì„±
    selector = ModelSelector()
    
    # ë‹¤ì–‘í•œ ì‘ì—… ìœ í˜•ì— ëŒ€í•´ ìµœì  ëª¨ë¸ ì„ íƒ
    test_tasks = [
        TaskType.IMAGE_ANALYSIS,
        TaskType.RAPID_RESPONSE,
        TaskType.DECISION_MAKING,
        TaskType.QUANTITATIVE
    ]
    
    for task in test_tasks:
        model = selector.select_model(task, priority='balanced')
        print(f"ğŸ“Œ {task.value}")
        print(f"  ì„ íƒ: {model.name}")
        print(f"  ì •í™•ë„: {model.accuracy_score*100:.0f}%")
        print(f"  ë¹„ìš©: ${model.cost_per_call}")
        print()
    
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
