"""
ReasoningEngine - Brainstemì˜ ë…¼ë¦¬ ì¶”ë¡ 
ì¦ê±° ê¸°ë°˜ ì¶”ë¡ , ì‹ ë¢°ë„ ê³„ì‚°, ì¸ê³¼ê´€ê³„ ì¶”ì 
"""

from typing import Dict, List, Tuple, Optional
from dataclasses import dataclass, field
from enum import Enum
import json


class ConfidenceLevel(Enum):
    """ì‹ ë¢°ë„ ë ˆë²¨"""
    VERY_LOW = 0.2
    LOW = 0.4
    MODERATE = 0.6
    HIGH = 0.8
    VERY_HIGH = 0.95


@dataclass
class Evidence:
    """ì¦ê±°"""
    claim: str
    supporting_evidence: List[str] = field(default_factory=list)
    contradicting_evidence: List[str] = field(default_factory=list)
    source_confidence: float = 0.7
    
    def strength(self) -> float:
        """ì¦ê±°ì˜ ê°•ë„ (0~1)"""
        support_score = len(self.supporting_evidence) * 0.15
        contra_score = len(self.contradicting_evidence) * 0.1
        base_score = self.source_confidence
        return min(0.95, max(0.1, base_score + support_score - contra_score))


@dataclass
class Reasoning:
    """ì¶”ë¡  ê²°ê³¼"""
    hypothesis: str
    confidence: float
    evidence: List[Evidence]
    logical_chain: List[str]  # ì¶”ë¡  ê³¼ì • ë‹¨ê³„ë³„ ê¸°ë¡
    potential_biases: List[str] = field(default_factory=list)
    alternative_explanations: List[str] = field(default_factory=list)


class ReasoningEngine:
    """
    ë…¼ë¦¬ ì¶”ë¡  ì—”ì§„
    - ì¦ê±° ê¸°ë°˜ ì¶”ë¡ 
    - ì‹ ë¢°ë„ ì •ëŸ‰ ê³„ì‚°
    - ì¸ê³¼ê´€ê³„ ì¶”ì 
    - í•œê³„ ì¸ì‹
    """
    
    def __init__(self):
        """ì¶”ë¡  ì—”ì§„ ì´ˆê¸°í™”"""
        self.reasoning_history: List[Reasoning] = []
        self.domain_expertise: Dict[str, float] = {
            "biology": 0.80,
            "finance": 0.60,
            "astronomy": 0.50,
            "literature": 0.70,
            "general": 0.65
        }
    
    def reason(
        self,
        hypothesis: str,
        evidence_list: List[Evidence],
        domain: str = "general",
        check_biases: bool = True
    ) -> Reasoning:
        """
        ê°€ì„¤ì„ ê²€ì¦í•˜ëŠ” ì¶”ë¡  ìˆ˜í–‰
        
        Args:
            hypothesis: ê²€ì¦í•  ê°€ì„¤
            evidence_list: ì¦ê±° ëª©ë¡
            domain: ë„ë©”ì¸ (ì‹ ë¢°ë„ì— ì˜í–¥)
            check_biases: í¸í–¥ ê²€í†  ì—¬ë¶€
        
        Returns:
            Reasoning: ì¶”ë¡  ê²°ê³¼
        """
        logical_chain = []
        total_confidence = 0.0
        
        # Step 1: ì¦ê±° í‰ê°€
        logical_chain.append(f"Step 1: Evaluating {len(evidence_list)} pieces of evidence")
        evidence_scores = [e.strength() for e in evidence_list]
        average_evidence_strength = sum(evidence_scores) / max(1, len(evidence_scores))
        
        # Step 2: ë„ë©”ì¸ ì‹ ë¢°ë„ ì ìš©
        logical_chain.append(f"Step 2: Domain expertise adjustment ({domain}: {self.domain_expertise[domain]})")
        domain_factor = self.domain_expertise.get(domain, 0.65)
        
        # Step 3: ì¢…í•© ì‹ ë¢°ë„ ê³„ì‚°
        logical_chain.append("Step 3: Synthesizing confidence score")
        total_confidence = (average_evidence_strength * 0.6) + (domain_factor * 0.4)
        
        # Step 4: ëª¨ìˆœ ê²€í† 
        logical_chain.append("Step 4: Checking for contradictions")
        contradictions = self._check_contradictions(evidence_list)
        if contradictions:
            total_confidence *= 0.85  # ì‹ ë¢°ë„ ê°ì†Œ
            logical_chain.append(f"   âš ï¸ Found {len(contradictions)} contradictions")
        
        # Step 5: í¸í–¥ ê²€í† 
        potential_biases = []
        alternative_explanations = []
        if check_biases:
            logical_chain.append("Step 5: Checking for biases")
            potential_biases = self._identify_biases(hypothesis, evidence_list)
            alternative_explanations = self._generate_alternatives(hypothesis, evidence_list)
        
        # ìµœì¢… ê²°ê³¼
        reasoning = Reasoning(
            hypothesis=hypothesis,
            confidence=min(0.98, max(0.15, total_confidence)),
            evidence=evidence_list,
            logical_chain=logical_chain,
            potential_biases=potential_biases,
            alternative_explanations=alternative_explanations
        )
        
        self.reasoning_history.append(reasoning)
        return reasoning
    
    def _check_contradictions(self, evidence_list: List[Evidence]) -> List[Tuple[str, str]]:
        """ì¦ê±° ê°„ ëª¨ìˆœ ì°¾ê¸°"""
        contradictions = []
        for i, e1 in enumerate(evidence_list):
            for e2 in evidence_list[i+1:]:
                # ê°„ë‹¨í•œ ëª¨ìˆœ ê²€ì‚¬: ì •ë°˜ëŒ€ ì£¼ì¥
                if e1.claim.lower() in str(e2.contradicting_evidence).lower():
                    contradictions.append((e1.claim, e2.claim))
        return contradictions
    
    def _identify_biases(self, hypothesis: str, evidence_list: List[Evidence]) -> List[str]:
        """ê°€ëŠ¥í•œ í¸í–¥ ì‹ë³„"""
        biases = []
        
        # ì„ íƒ í¸í–¥ ê²€ì‚¬
        if len(evidence_list) < 3:
            biases.append("selection_bias: Limited evidence sample")
        
        # í™•ì¦ í¸í–¥ ê²€ì‚¬
        supporting_count = sum(len(e.supporting_evidence) for e in evidence_list)
        contradicting_count = sum(len(e.contradicting_evidence) for e in evidence_list)
        if supporting_count > contradicting_count * 2:
            biases.append("confirmation_bias: Weighted towards supporting evidence")
        
        # ì¶œì²˜ ì‹ ë¢°ë„ ê²€ì‚¬
        low_confidence_sources = [e for e in evidence_list if e.source_confidence < 0.5]
        if low_confidence_sources:
            biases.append(f"source_reliability: {len(low_confidence_sources)} low-confidence sources")
        
        return biases
    
    def _generate_alternatives(self, hypothesis: str, evidence_list: List[Evidence]) -> List[str]:
        """ëŒ€ì•ˆì  ì„¤ëª… ìƒì„±"""
        alternatives = []
        
        # ì¦ê±°ë¡œë¶€í„° ë‹¤ë¥¸ ê²°ë¡  ë„ì¶œ ê°€ëŠ¥ì„±
        if len(evidence_list) > 0:
            alternatives.append("Alternative: Evidence could support multiple interpretations")
            alternatives.append("Alternative: Missing confounding variables not accounted for")
            alternatives.append("Alternative: Temporal relationship unclear")
        
        return alternatives[:3]  # ìƒìœ„ 3ê°œë§Œ
    
    def assess_confidence(self, domain: str = "general") -> Dict:
        """ë„ë©”ì¸ë³„ ì‹ ë¢°ë„ í‰ê°€"""
        return {
            "domain": domain,
            "expertise_level": self.domain_expertise.get(domain, 0.0),
            "interpretation": self._interpret_confidence(self.domain_expertise.get(domain, 0.0))
        }
    
    def _interpret_confidence(self, confidence: float) -> str:
        """ì‹ ë¢°ë„ë¥¼ ì¸ê°„ ì–¸ì–´ë¡œ ë³€í™˜"""
        if confidence >= 0.85:
            return "Very confident"
        elif confidence >= 0.70:
            return "Confident"
        elif confidence >= 0.55:
            return "Moderately confident"
        elif confidence >= 0.40:
            return "Low confidence"
        else:
            return "Very low confidence - requires expert review"
    
    def get_reasoning_summary(self, reasoning: Reasoning) -> str:
        """ì¶”ë¡  ê³¼ì • ìš”ì•½"""
        summary = f"""
        ğŸ§  REASONING SUMMARY
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        
        Hypothesis: {reasoning.hypothesis}
        Confidence: {reasoning.confidence:.1%}
        
        Evidence Evaluated: {len(reasoning.evidence)}
        
        Reasoning Chain:
        {chr(10).join('  ' + step for step in reasoning.logical_chain)}
        
        Potential Biases:
        {chr(10).join('  - ' + bias for bias in reasoning.potential_biases) if reasoning.potential_biases else '  None identified'}
        
        Alternative Explanations:
        {chr(10).join('  - ' + alt for alt in reasoning.alternative_explanations) if reasoning.alternative_explanations else '  None'}
        
        â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        """
        return summary


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    engine = ReasoningEngine()
    
    # ì¦ê±° ì¤€ë¹„
    evidence1 = Evidence(
        claim="Organoids can model organ development",
        supporting_evidence=["Nature paper 2023", "Cell Reports 2022"],
        contradicting_evidence=["Some limitations exist"],
        source_confidence=0.85
    )
    
    evidence2 = Evidence(
        claim="Uterine organoids show endometrial features",
        supporting_evidence=["EMBO 2023", "Dev Cell 2023"],
        source_confidence=0.80
    )
    
    # ì¶”ë¡  ìˆ˜í–‰
    result = engine.reason(
        hypothesis="Organoids can accurately model uterine pathology",
        evidence_list=[evidence1, evidence2],
        domain="biology",
        check_biases=True
    )
    
    print(engine.get_reasoning_summary(result))
