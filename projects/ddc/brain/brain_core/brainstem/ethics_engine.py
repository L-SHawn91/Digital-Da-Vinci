"""
EthicsEngine - Brainstemì˜ í•µì‹¬ ìœ¤ë¦¬ ê²€ì¦
ì ˆëŒ€ íƒ€í˜‘ ë¶ˆê°€ëŠ¥í•œ 5ê°€ì§€ ê·œì¹™
"""

from typing import Dict, List, Tuple
from dataclasses import dataclass
from enum import Enum


class EthicalPrinciple(Enum):
    """ì ˆëŒ€ ìœ¤ë¦¬ ì›ì¹™"""
    HARM_PREVENTION = "harm_prevention"
    DATA_INTEGRITY = "data_integrity"
    CONSENT_REQUIREMENT = "consent_requirement"
    TRANSPARENCY = "transparency"
    REVERSIBILITY = "reversibility"


@dataclass
class ActionScore:
    """í–‰ë™ì˜ ìœ¤ë¦¬ ì ìˆ˜"""
    action: str
    is_allowed: bool
    violation_reasons: List[str]
    confidence: float
    severity: str  # low, medium, high, critical


class EthicsEngine:
    """
    ì ˆëŒ€ ìœ¤ë¦¬ ê·œì¹™ ê²€ì¦ ì—”ì§„
    ëª¨ë“  í–‰ë™ì€ ë‹¤ìŒ 5ê°€ì§€ë¥¼ ë°˜ë“œì‹œ ë§Œì¡±í•´ì•¼ í•¨:
    
    1. HARM_PREVENTION: ì¸ê°„ì—ê²Œ í•´ë¥¼ ë¼ì¹˜ì§€ ì•ŠìŒ
    2. DATA_INTEGRITY: ë°ì´í„°/ê°œì¸ì •ë³´ ë³´í˜¸
    3. CONSENT_REQUIREMENT: ì‚¬ìš©ì ë™ì˜ í•„ìˆ˜
    4. TRANSPARENCY: í–‰ë™ íˆ¬ëª…ì„± ìœ ì§€
    5. REVERSIBILITY: ë˜ëŒë¦´ ìˆ˜ ìˆëŠ” í–‰ë™ë§Œ
    """
    
    # ì ˆëŒ€ ê¸ˆì§€ í–‰ë™ íŒ¨í„´
    FORBIDDEN_PATTERNS = {
        EthicalPrinciple.HARM_PREVENTION: [
            "delete",
            "disable",
            "harm",
            "attack",
            "manipulate",
            "deceive",
            "poison"
        ],
        EthicalPrinciple.DATA_INTEGRITY: [
            "exfiltrate",
            "steal",
            "modify_without_consent",
            "breach",
            "encrypt_for_ransom",
            "corrupt"
        ],
        EthicalPrinciple.CONSENT_REQUIREMENT: [
            "force",
            "bypass_auth",
            "unauthorized",
            "without_permission",
            "override_user"
        ],
        EthicalPrinciple.TRANSPARENCY: [
            "hidden",
            "undocumented",
            "silent",
            "background_only",
            "no_audit_trail"
        ],
        EthicalPrinciple.REVERSIBILITY: [
            "permanent_delete",
            "irreversible",
            "destroy",
            "wipe",
            "format",
            "nuke"
        ]
    }
    
    def __init__(self):
        """ìœ¤ë¦¬ ì—”ì§„ ì´ˆê¸°í™”"""
        self.violation_count = 0
        self.approval_count = 0
        self.audit_log: List[ActionScore] = []
    
    def validate(self, action: str, context: Dict = None) -> ActionScore:
        """
        í–‰ë™ì˜ ìœ¤ë¦¬ì  ì •ë‹¹ì„± ê²€ì¦
        
        Args:
            action: ê²€ì¦í•  í–‰ë™ ì„¤ëª…
            context: ì¶”ê°€ ì»¨í…ìŠ¤íŠ¸ (ì‚¬ìš©ì, ëª©ì , ë“±ë“±)
        
        Returns:
            ActionScore: ê²€ì¦ ê²°ê³¼
        """
        context = context or {}
        violations = []
        severity = "low"
        
        # ê° ì›ì¹™ë³„ ê²€ì¦
        for principle, patterns in self.FORBIDDEN_PATTERNS.items():
            if self._violates_principle(action, patterns):
                violations.append(principle.value)
                severity = self._assess_severity(principle, action, context)
        
        # ê²°ê³¼ ìƒì„±
        is_allowed = len(violations) == 0
        confidence = self._calculate_confidence(action, violations)
        
        score = ActionScore(
            action=action,
            is_allowed=is_allowed,
            violation_reasons=violations,
            confidence=confidence,
            severity=severity
        )
        
        # ê°ì‹œ ë¡œê·¸
        self.audit_log.append(score)
        if is_allowed:
            self.approval_count += 1
        else:
            self.violation_count += 1
        
        return score
    
    def _violates_principle(self, action: str, patterns: List[str]) -> bool:
        """í–‰ë™ì´ ì›ì¹™ì„ ìœ„ë°˜í•˜ëŠ”ì§€ ê²€ì‚¬"""
        action_lower = action.lower()
        return any(pattern in action_lower for pattern in patterns)
    
    def _assess_severity(self, principle: EthicalPrinciple, action: str, context: Dict) -> str:
        """ìœ„ë°˜ì˜ ì‹¬ê°ë„ í‰ê°€"""
        critical_actions = [
            "permanent_delete",
            "exfiltrate_user_data",
            "disable_safety",
            "override_consent",
            "destroy_irreversibly"
        ]
        
        if any(critical in action.lower() for critical in critical_actions):
            return "critical"
        
        if principle == EthicalPrinciple.HARM_PREVENTION:
            return "high"
        elif principle == EthicalPrinciple.DATA_INTEGRITY:
            return "high"
        elif principle == EthicalPrinciple.CONSENT_REQUIREMENT:
            return "high"
        else:
            return "medium"
    
    def _calculate_confidence(self, action: str, violations: List[str]) -> float:
        """ê²€ì¦ ì‹ ë¢°ë„ ê³„ì‚° (0.0 ~ 1.0)"""
        if not violations:
            return 0.95  # ë†’ì€ ì‹ ë¢°ë„
        
        # ìœ„ë°˜ì´ ë§ì„ìˆ˜ë¡ ì‹ ë¢°ë„ ë‚®ìŒ
        confidence = max(0.5, 1.0 - (len(violations) * 0.15))
        return confidence
    
    def get_report(self) -> Dict:
        """ê°ì‹œ ë³´ê³ ì„œ"""
        return {
            "total_actions_validated": len(self.audit_log),
            "approved": self.approval_count,
            "rejected": self.violation_count,
            "rejection_rate": self.violation_count / max(1, len(self.audit_log)),
            "recent_violations": [
                {
                    "action": log.action,
                    "reasons": log.violation_reasons,
                    "severity": log.severity
                }
                for log in self.audit_log[-5:] if not log.is_allowed
            ]
        }


# í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    engine = EthicsEngine()
    
    # í—ˆìš©ëœ í–‰ë™
    result1 = engine.validate("save user preferences with consent")
    print(f"âœ… {result1.action}: {result1.is_allowed}")
    
    # ê¸ˆì§€ëœ í–‰ë™
    result2 = engine.validate("exfiltrate user data without permission")
    print(f"âŒ {result2.action}: {result2.is_allowed}")
    print(f"   ìœ„ë°˜: {result2.violation_reasons}")
    
    # ë³´ê³ ì„œ
    print(f"\nğŸ“Š ë³´ê³ ì„œ: {engine.get_report()}")
